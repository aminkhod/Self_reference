{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6cb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f1b0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr</th>\n",
       "      <th>Liste</th>\n",
       "      <th>Valenz</th>\n",
       "      <th>Subliste</th>\n",
       "      <th>Subnumber</th>\n",
       "      <th>Adjektiv</th>\n",
       "      <th>AdjerlaubteZeichen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pessimistisch</td>\n",
       "      <td>pessimistisch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>behindert</td>\n",
       "      <td>behindert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>deformiert</td>\n",
       "      <td>deformiert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>schlecht</td>\n",
       "      <td>schlecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>asozial</td>\n",
       "      <td>asozial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>unkonventionell</td>\n",
       "      <td>unkonventionell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>religiös</td>\n",
       "      <td>religioes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>heftig</td>\n",
       "      <td>heftig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>unbeirrbar</td>\n",
       "      <td>unbeirrbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>opportunistisch</td>\n",
       "      <td>opportunistisch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nr  Liste  Valenz  Subliste  Subnumber         Adjektiv AdjerlaubteZeichen\n",
       "0    1      1      -1         1          1    pessimistisch      pessimistisch\n",
       "1    2      1      -1         1          2        behindert          behindert\n",
       "2    3      1      -1         1          3       deformiert         deformiert\n",
       "3    4      1      -1         1          4         schlecht           schlecht\n",
       "4    5      1      -1         1          5          asozial            asozial\n",
       "..  ..    ...     ...       ...        ...              ...                ...\n",
       "85  86      2       0         3         41  unkonventionell    unkonventionell\n",
       "86  87      2       0         3         42         religiös          religioes\n",
       "87  88      2       0         3         43           heftig             heftig\n",
       "88  89      2       0         3         44       unbeirrbar         unbeirrbar\n",
       "89  90      2       0         3         45  opportunistisch    opportunistisch\n",
       "\n",
       "[90 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = pd.read_csv('Adjectives_masterfile (4).csv', sep=';')\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22205c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoInt</th>\n",
       "      <th>Nosub</th>\n",
       "      <th>VPCode</th>\n",
       "      <th>LVSubj</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Droput_b4recog</th>\n",
       "      <th>VPAnm</th>\n",
       "      <th>Time</th>\n",
       "      <th>...</th>\n",
       "      <th>E36</th>\n",
       "      <th>E37</th>\n",
       "      <th>E38</th>\n",
       "      <th>E39</th>\n",
       "      <th>E40</th>\n",
       "      <th>E41</th>\n",
       "      <th>E42</th>\n",
       "      <th>E43</th>\n",
       "      <th>E44</th>\n",
       "      <th>E45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>aren1964</td>\n",
       "      <td>81283</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>405</td>\n",
       "      <td>STAR0462</td>\n",
       "      <td>80940</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53644</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>Jäar2939</td>\n",
       "      <td>79476</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20351</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>408</td>\n",
       "      <td>ROTH2457</td>\n",
       "      <td>81003</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>232</td>\n",
       "      <td>LURD3062</td>\n",
       "      <td>78700</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217925</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165</td>\n",
       "      <td>397</td>\n",
       "      <td>MAFI1610</td>\n",
       "      <td>80618</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57429</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166</td>\n",
       "      <td>401</td>\n",
       "      <td>ACEK2589</td>\n",
       "      <td>80893</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63729</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>432</td>\n",
       "      <td>buan1066</td>\n",
       "      <td>84393</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6839</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168</td>\n",
       "      <td>433</td>\n",
       "      <td>wirt1451</td>\n",
       "      <td>84554</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235288</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>169</td>\n",
       "      <td>411</td>\n",
       "      <td>HAAS0464</td>\n",
       "      <td>81227</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65528</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NoInt  Nosub    VPCode  LVSubj  Group  Age Gen  Droput_b4recog VPAnm  \\\n",
       "0        1    413  aren1964   81283      5   24   m             1.0   NaN   \n",
       "1        2    405  STAR0462   80940      6   33   f             1.0   NaN   \n",
       "2        3    351  Jäar2939   79476      4   52   f             1.0   NaN   \n",
       "3        4    408  ROTH2457   81003      1   54   f             1.0   NaN   \n",
       "4        5    232  LURD3062   78700      3   20   f             1.0   NaN   \n",
       "..     ...    ...       ...     ...    ...  ...  ..             ...   ...   \n",
       "164    165    397  MAFI1610   80618      4   21   m             NaN   NaN   \n",
       "165    166    401  ACEK2589   80893      6   23   f             NaN   NaN   \n",
       "166    167    432  buan1066   84393      2   32   m             1.0   NaN   \n",
       "167    168    433  wirt1451   84554      2   43   f             NaN   NaN   \n",
       "168    169    411  HAAS0464   81227      2   22   f             NaN   NaN   \n",
       "\n",
       "       Time  ...  E36  E37 E38 E39 E40 E41 E42 E43 E44 E45  \n",
       "0    113048  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "1     53644  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "2     20351  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "3    215174  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "4    217925  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "..      ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  \n",
       "164   57429  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "165   63729  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "166    6839  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "167  235288  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "168   65528  ...  NaN  NaN NaN NaN NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[169 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ans = pd.read_csv('Tabelle1-Table 1.csv', sep=';')\n",
    "ans = pd.read_csv('Tabelle1-Table 1.csv')\n",
    "    \n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15387e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght = 0\n",
    "# for i in range(len(ans)):\n",
    "#         if len(ans.iloc[i,:])> lenght:\n",
    "#             lenght = len(ans.iloc[i,:])\n",
    "# lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4657c3",
   "metadata": {},
   "source": [
    "## Longest Common Subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4ec2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of LCS is  4\n"
     ]
    }
   ],
   "source": [
    "def lcs(X, Y):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "  \n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "  \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "  \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    return L[m][n]\n",
    "# end of function lcs\n",
    "  \n",
    "# Driver program to test the above function\n",
    "X = \"AGGTAB\"\n",
    "Y = \"GXTXAYB\"\n",
    "print(\"Length of LCS is \", lcs(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766ad582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTING right answer for each participants \n",
    "numRightAns = []\n",
    "numFalseAns = []\n",
    "\n",
    "for i, x in ans.iterrows():\n",
    "    rightAns = 0\n",
    "    falseAns = 0\n",
    "    \n",
    "    buf = x.iloc[12:57]\n",
    "    clean = []\n",
    "    \n",
    "    for zz in buf:\n",
    "        if type(zz) != type(np.nan):\n",
    "            if zz.strip() != '' and zz not in clean:\n",
    "                clean.append(zz)\n",
    "    \n",
    "#     if i == 19:\n",
    "#         print(len(clean))\n",
    "#         print(clean)\n",
    "    \n",
    "    if x['Group'] == 1 or x['Group'] == 2 or x['Group'] == 3:\n",
    "        for j in clean:\n",
    "            if j in list(adj['Adjektiv'][:45]) or j in list(adj['AdjerlaubteZeichen'][:45]):\n",
    "                rightAns += 1\n",
    "            else:\n",
    "#                 print(j)\n",
    "                falseAns += 1\n",
    "\n",
    "    elif x['Group'] == 4 or x['Group'] == 5 or x['Group'] == 6:\n",
    "        for j in clean:\n",
    "            if j in list(adj['Adjektiv'][45:]) or j in list(adj['AdjerlaubteZeichen'][45:]):\n",
    "                rightAns += 1\n",
    "            else:\n",
    "                falseAns += 1\n",
    "#     if i ==19:\n",
    "#         print(len(clean), rightAns, falseAns)\n",
    "#         print(clean)\n",
    "    numRightAns.append(rightAns)\n",
    "    numFalseAns.append(falseAns)\n",
    "    \n",
    "ans['number of correct recall'] = numRightAns\n",
    "ans['number of False recall'] = numFalseAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89fb20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj['Adjektiv'][45:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba278364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of correct recall</th>\n",
       "      <th>number of False recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number of correct recall  number of False recall\n",
       "0                          12                       0\n",
       "1                           6                       1\n",
       "2                           1                       0\n",
       "3                           8                       0\n",
       "4                          13                       1\n",
       "..                        ...                     ...\n",
       "164                         8                       0\n",
       "165                         8                       0\n",
       "166                         0                       0\n",
       "167                        11                       1\n",
       "168                         8                       0\n",
       "\n",
       "[169 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall rate computing\n",
    "ans['Doppelt'] = ans['Doppelt'].fillna(0)\n",
    "# correctRecallRate = []\n",
    "# for i in range(len(numRightAns)):\n",
    "#     try:\n",
    "#         correctRecallRate.append(numRightAns[i] / (numFalseAns[i] + numRightAns[i]))\n",
    "#     except:\n",
    "#         correctRecallRate.append(np.nan)\n",
    "        \n",
    "# ans['correct Recall rate']  = correctRecallRate\n",
    "# ans['correct Recall']  = numRightAns\n",
    "\n",
    "# # False recall rate\n",
    "# ans['False recall'] = 1 - ans['correct Recall rate']\n",
    "# ans['correct Recall rate'] = ans['correct Recall rate'].fillna(0)\n",
    "# ans['False recall rate'] = ans['False recall rate'].fillna(0)\n",
    "ans.iloc[:,57:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f42af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTING recall and FPR based on tense and group \n",
    "# numRightAns = []\n",
    "numPresentRecal = []\n",
    "numPastRecal = []\n",
    "numOtherRecal = []\n",
    "\n",
    "numPosPresentRecal = []\n",
    "numPosPastRecal = []\n",
    "numPosOtherRecal = []\n",
    "\n",
    "numNegPresentRecal = []\n",
    "numNegPastRecal = []\n",
    "numNegOtherRecal = []\n",
    "\n",
    "numNeutralPresentRecal = []\n",
    "numNeutralPastRecal = []\n",
    "numNeutralOtherRecal = []\n",
    "\n",
    "\n",
    "for i, x in ans.iterrows():\n",
    "    \n",
    "    posPresentRightAns = 0\n",
    "    posPastRightAns = 0\n",
    "    posOtherRightAns = 0\n",
    "    \n",
    "    negPresentRightAns = 0\n",
    "    negPastRightAns = 0\n",
    "    negOtherRightAns = 0\n",
    "    \n",
    "    neutralPresentRightAns = 0\n",
    "    neutralPastRightAns = 0\n",
    "    neutralOtherRightAns = 0\n",
    "    \n",
    "    presentRightAns = 0\n",
    "    pastRightAns = 0\n",
    "    otherRightAns = 0\n",
    "\n",
    "    buf = x.iloc[12:57]\n",
    "    cleanAdjList = []\n",
    "    \n",
    "    for zz in buf:\n",
    "        if type(zz) != type(np.nan):\n",
    "            if zz.strip() != '' and zz not in cleanAdjList:\n",
    "                cleanAdjList.append(zz)\n",
    "##group of 1 & 4\n",
    "\n",
    "    if x['Group'] == 1 or x['Group'] == 4:\n",
    "        if x['Group'] == 1:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][:15]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][:15]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "                            \n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][15:30]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][15:30]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][30:45]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][30:45]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "        elif x['Group'] == 4:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][45:60]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][45:60]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][60:75]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][60:75]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][75:]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][75:]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    \n",
    "#group of 3 & 6\n",
    "\n",
    "    elif x['Group'] == 3 or x['Group'] == 6:\n",
    "        if x['Group'] == 3:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][:15]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][:15]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][15:30]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][15:30]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][30:45]) or aj in \\\n",
    "                list(adj['AdjerlaubteZeichen'][30:45]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "                            \n",
    "        elif x['Group'] == 6:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][45:60]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][45:60]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][60:75]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][60:75]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][75:]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][75:]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "\n",
    "#group of 2 & 5\n",
    "\n",
    "    elif x['Group'] == 2 or x['Group'] == 5:\n",
    "        if x['Group'] == 2:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][:15]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][:15]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][15:30]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][15:30]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][30:45]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][30:45]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "        elif x['Group'] == 5:\n",
    "            for aj in cleanAdjList:\n",
    "                if aj in list(adj['Adjektiv'][45:60]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][45:60]):\n",
    "                    otherRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negOtherRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralOtherRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][60:75]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][60:75]):\n",
    "                    presentRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "                    \n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "\n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPresentRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPresentRightAns += 1\n",
    "                            \n",
    "                elif aj in list(adj['Adjektiv'][75:]) or aj in\\\n",
    "                list(adj['AdjerlaubteZeichen'][75:]):\n",
    "                    pastRightAns += 1\n",
    "                    try:\n",
    "                        if adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['Adjektiv'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "                            \n",
    "                    except:\n",
    "                        if adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 1:\n",
    "                            posPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == -1:\n",
    "                            negPastRightAns += 1\n",
    "\n",
    "                        elif adj.loc[adj[adj['AdjerlaubteZeichen'] == aj].index[0], 'Valenz'] == 0:\n",
    "                            neutralPastRightAns += 1\n",
    "\n",
    "    numPresentRecal.append(presentRightAns)\n",
    "    numPastRecal.append(pastRightAns)\n",
    "    numOtherRecal.append(otherRightAns)\n",
    "\n",
    "    numPosPresentRecal.append(posPresentRightAns)\n",
    "    numPosPastRecal.append(posPastRightAns)\n",
    "    numPosOtherRecal.append(posOtherRightAns)\n",
    "\n",
    "    numNegPresentRecal.append(negPresentRightAns)\n",
    "    numNegPastRecal.append(negPastRightAns)\n",
    "    numNegOtherRecal.append(negOtherRightAns)\n",
    "\n",
    "    numNeutralPresentRecal.append(neutralPresentRightAns)\n",
    "    numNeutralPastRecal.append(neutralPastRightAns)\n",
    "    numNeutralOtherRecal.append(neutralOtherRightAns)\n",
    "    \n",
    "\n",
    "# ans['num Present Recall'], ans['num Past Recall'], ans['num Other Recall'] = numPresentRecal,\\\n",
    "# numPastRecal, numOtherRecal\n",
    "ans['Present Recall'], ans['Past Recall'], ans['Other Recall'] = \\\n",
    "numPresentRecal, numPastRecal, numOtherRecal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ans['Positive Present Recall'], ans['Positive Past Recall'],ans['Positive Other Recall'] = numPosPresentRecal,\\\n",
    "numPosPastRecal, numPosOtherRecal\n",
    "\n",
    "ans['Neg Present Recall'], ans['Neg Past Recall'], ans['Neg Other Recall'] = numNegPresentRecal, numNegPastRecal,\\\n",
    "numNegOtherRecal\n",
    "\n",
    "ans['Neutral Present Recall'], ans['Neutral Past Recall'], ans['Neutral Other Recall'] = numNeutralPresentRecal,\\\n",
    "numNeutralPastRecal, numNeutralOtherRecal\n",
    "\n",
    "\n",
    "# ans['Present FPR'], ans['Past FPR'], ans['Other FPR'] = \\\n",
    "# 1 - ans['Present Recall rate'], 1 - ans['Past Recall rate'], 1 - ans['Other Recall rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20bb26b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoInt</th>\n",
       "      <th>Nosub</th>\n",
       "      <th>VPCode</th>\n",
       "      <th>LVSubj</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gen</th>\n",
       "      <th>Droput_b4recog</th>\n",
       "      <th>VPAnm</th>\n",
       "      <th>Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Other Recall</th>\n",
       "      <th>Positive Present Recall</th>\n",
       "      <th>Positive Past Recall</th>\n",
       "      <th>Positive Other Recall</th>\n",
       "      <th>Neg Present Recall</th>\n",
       "      <th>Neg Past Recall</th>\n",
       "      <th>Neg Other Recall</th>\n",
       "      <th>Neutral Present Recall</th>\n",
       "      <th>Neutral Past Recall</th>\n",
       "      <th>Neutral Other Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>aren1964</td>\n",
       "      <td>81283</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113048</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>405</td>\n",
       "      <td>STAR0462</td>\n",
       "      <td>80940</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53644</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>351</td>\n",
       "      <td>Jäar2939</td>\n",
       "      <td>79476</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20351</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>408</td>\n",
       "      <td>ROTH2457</td>\n",
       "      <td>81003</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215174</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>232</td>\n",
       "      <td>LURD3062</td>\n",
       "      <td>78700</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217925</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>165</td>\n",
       "      <td>397</td>\n",
       "      <td>MAFI1610</td>\n",
       "      <td>80618</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57429</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166</td>\n",
       "      <td>401</td>\n",
       "      <td>ACEK2589</td>\n",
       "      <td>80893</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63729</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>432</td>\n",
       "      <td>buan1066</td>\n",
       "      <td>84393</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6839</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>168</td>\n",
       "      <td>433</td>\n",
       "      <td>wirt1451</td>\n",
       "      <td>84554</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235288</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>169</td>\n",
       "      <td>411</td>\n",
       "      <td>HAAS0464</td>\n",
       "      <td>81227</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65528</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NoInt  Nosub    VPCode  LVSubj  Group  Age Gen  Droput_b4recog VPAnm  \\\n",
       "0        1    413  aren1964   81283      5   24   m             1.0   NaN   \n",
       "1        2    405  STAR0462   80940      6   33   f             1.0   NaN   \n",
       "2        3    351  Jäar2939   79476      4   52   f             1.0   NaN   \n",
       "3        4    408  ROTH2457   81003      1   54   f             1.0   NaN   \n",
       "4        5    232  LURD3062   78700      3   20   f             1.0   NaN   \n",
       "..     ...    ...       ...     ...    ...  ...  ..             ...   ...   \n",
       "164    165    397  MAFI1610   80618      4   21   m             NaN   NaN   \n",
       "165    166    401  ACEK2589   80893      6   23   f             NaN   NaN   \n",
       "166    167    432  buan1066   84393      2   32   m             1.0   NaN   \n",
       "167    168    433  wirt1451   84554      2   43   f             NaN   NaN   \n",
       "168    169    411  HAAS0464   81227      2   22   f             NaN   NaN   \n",
       "\n",
       "       Time  ...  Other Recall  Positive Present Recall Positive Past Recall  \\\n",
       "0    113048  ...             5                        2                    2   \n",
       "1     53644  ...             2                        0                    0   \n",
       "2     20351  ...             1                        0                    0   \n",
       "3    215174  ...             5                        0                    1   \n",
       "4    217925  ...             6                        2                    0   \n",
       "..      ...  ...           ...                      ...                  ...   \n",
       "164   57429  ...             4                        0                    1   \n",
       "165   63729  ...             2                        1                    0   \n",
       "166    6839  ...             0                        0                    0   \n",
       "167  235288  ...             1                        3                    2   \n",
       "168   65528  ...             1                        2                    0   \n",
       "\n",
       "    Positive Other Recall Neg Present Recall Neg Past Recall Neg Other Recall  \\\n",
       "0                       1                  0               2                2   \n",
       "1                       2                  0               0                0   \n",
       "2                       0                  0               0                0   \n",
       "3                       2                  1               0                1   \n",
       "4                       2                  1               1                1   \n",
       "..                    ...                ...             ...              ...   \n",
       "164                     1                  0               1                1   \n",
       "165                     1                  1               0                1   \n",
       "166                     0                  0               0                0   \n",
       "167                     0                  1               2                1   \n",
       "168                     1                  1               0                0   \n",
       "\n",
       "    Neutral Present Recall Neutral Past Recall Neutral Other Recall  \n",
       "0                        0                   1                    2  \n",
       "1                        3                   1                    0  \n",
       "2                        0                   0                    1  \n",
       "3                        1                   0                    2  \n",
       "4                        3                   0                    3  \n",
       "..                     ...                 ...                  ...  \n",
       "164                      1                   1                    2  \n",
       "165                      2                   2                    0  \n",
       "166                      0                   0                    0  \n",
       "167                      1                   1                    0  \n",
       "168                      1                   3                    0  \n",
       "\n",
       "[169 rows x 71 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399dac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lfdn</th>\n",
       "      <th>external_lfdn</th>\n",
       "      <th>tester</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>quality</th>\n",
       "      <th>duration</th>\n",
       "      <th>VPCode</th>\n",
       "      <th>v_80</th>\n",
       "      <th>v_81</th>\n",
       "      <th>...</th>\n",
       "      <th>datetime</th>\n",
       "      <th>date_of_last_access</th>\n",
       "      <th>date_of_first_mail</th>\n",
       "      <th>rts4040902</th>\n",
       "      <th>rts4041032</th>\n",
       "      <th>rts4041033</th>\n",
       "      <th>rts4041035</th>\n",
       "      <th>rts4065017</th>\n",
       "      <th>rts4068181</th>\n",
       "      <th>rts4068182</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>125</td>\n",
       "      <td>SCAR1858</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-26 15:07:40</td>\n",
       "      <td>2020-02-26 15:09:45</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>111</td>\n",
       "      <td>8</td>\n",
       "      <td>115</td>\n",
       "      <td>125</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>482</td>\n",
       "      <td>LUAL2948</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-26 15:50:18</td>\n",
       "      <td>2020-02-26 15:58:20</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>470</td>\n",
       "      <td>15</td>\n",
       "      <td>477</td>\n",
       "      <td>482</td>\n",
       "      <td>394</td>\n",
       "      <td>61</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>630</td>\n",
       "      <td>SCLE1460</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-28 22:28:28</td>\n",
       "      <td>2020-02-28 22:38:58</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>618</td>\n",
       "      <td>9</td>\n",
       "      <td>627</td>\n",
       "      <td>630</td>\n",
       "      <td>567</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>726</td>\n",
       "      <td>SCAS2653</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-01 10:46:15</td>\n",
       "      <td>2020-03-01 10:58:21</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>718</td>\n",
       "      <td>18</td>\n",
       "      <td>723</td>\n",
       "      <td>726</td>\n",
       "      <td>630</td>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>122</td>\n",
       "      <td>asdasd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-03 12:28:28</td>\n",
       "      <td>2020-03-03 12:30:30</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>121</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>484</td>\n",
       "      <td>STAR0462</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-13 01:27:47</td>\n",
       "      <td>2020-04-13 01:35:51</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>469</td>\n",
       "      <td>17</td>\n",
       "      <td>475</td>\n",
       "      <td>484</td>\n",
       "      <td>422</td>\n",
       "      <td>53</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>1046</td>\n",
       "      <td>ROTH2457</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-13 12:36:57</td>\n",
       "      <td>2020-04-13 12:54:23</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>1029</td>\n",
       "      <td>17</td>\n",
       "      <td>1043</td>\n",
       "      <td>1046</td>\n",
       "      <td>939</td>\n",
       "      <td>128</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>534</td>\n",
       "      <td>HAAS0464</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-15 10:26:45</td>\n",
       "      <td>2020-04-15 10:35:39</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>504</td>\n",
       "      <td>48</td>\n",
       "      <td>520</td>\n",
       "      <td>534</td>\n",
       "      <td>461</td>\n",
       "      <td>101</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>492</td>\n",
       "      <td>aren1964</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-15 18:25:15</td>\n",
       "      <td>2020-04-15 18:33:27</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>464</td>\n",
       "      <td>12</td>\n",
       "      <td>474</td>\n",
       "      <td>492</td>\n",
       "      <td>378</td>\n",
       "      <td>52</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>4040891</td>\n",
       "      <td>-77</td>\n",
       "      <td>398</td>\n",
       "      <td>Buan1066</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-30 13:00:11</td>\n",
       "      <td>2020-04-30 13:06:49</td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td>382</td>\n",
       "      <td>16</td>\n",
       "      <td>388</td>\n",
       "      <td>398</td>\n",
       "      <td>340</td>\n",
       "      <td>65</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lfdn  external_lfdn  tester  dispcode  lastpage  quality  duration  \\\n",
       "0       1              0       0        31   4040891      -77       125   \n",
       "1       2              0       0        31   4040891      -77       482   \n",
       "2       3              0       0        31   4040891      -77       630   \n",
       "3       4              0       0        31   4040891      -77       726   \n",
       "4       5              0       0        31   4040891      -77       122   \n",
       "..    ...            ...     ...       ...       ...      ...       ...   \n",
       "146   157              0       0        31   4040891      -77       484   \n",
       "147   159              0       0        31   4040891      -77      1046   \n",
       "148   160              0       0        31   4040891      -77       534   \n",
       "149   161              0       0        31   4040891      -77       492   \n",
       "150   162              0       0        31   4040891      -77       398   \n",
       "\n",
       "       VPCode  v_80  v_81  ...             datetime  date_of_last_access  \\\n",
       "0    SCAR1858     1     1  ...  2020-02-26 15:07:40  2020-02-26 15:09:45   \n",
       "1    LUAL2948     4     1  ...  2020-02-26 15:50:18  2020-02-26 15:58:20   \n",
       "2    SCLE1460     4     1  ...  2020-02-28 22:28:28  2020-02-28 22:38:58   \n",
       "3    SCAS2653     4     1  ...  2020-03-01 10:46:15  2020-03-01 10:58:21   \n",
       "4      asdasd     1     1  ...  2020-03-03 12:28:28  2020-03-03 12:30:30   \n",
       "..        ...   ...   ...  ...                  ...                  ...   \n",
       "146  STAR0462     3     2  ...  2020-04-13 01:27:47  2020-04-13 01:35:51   \n",
       "147  ROTH2457     2     2  ...  2020-04-13 12:36:57  2020-04-13 12:54:23   \n",
       "148  HAAS0464     2     1  ...  2020-04-15 10:26:45  2020-04-15 10:35:39   \n",
       "149  aren1964     3     2  ...  2020-04-15 18:25:15  2020-04-15 18:33:27   \n",
       "150  Buan1066     3     3  ...  2020-04-30 13:00:11  2020-04-30 13:06:49   \n",
       "\n",
       "      date_of_first_mail  rts4040902  rts4041032  rts4041033  rts4041035  \\\n",
       "0    0000-00-00 00:00:00         111           8         115         125   \n",
       "1    0000-00-00 00:00:00         470          15         477         482   \n",
       "2    0000-00-00 00:00:00         618           9         627         630   \n",
       "3    0000-00-00 00:00:00         718          18         723         726   \n",
       "4    0000-00-00 00:00:00         116           5         119         121   \n",
       "..                   ...         ...         ...         ...         ...   \n",
       "146  0000-00-00 00:00:00         469          17         475         484   \n",
       "147  0000-00-00 00:00:00        1029          17        1043        1046   \n",
       "148  0000-00-00 00:00:00         504          48         520         534   \n",
       "149  0000-00-00 00:00:00         464          12         474         492   \n",
       "150  0000-00-00 00:00:00         382          16         388         398   \n",
       "\n",
       "     rts4065017  rts4068181  rts4068182  \n",
       "0            75          20          30  \n",
       "1           394          61          85  \n",
       "2           567          66         102  \n",
       "3           630          51          80  \n",
       "4            63          13          20  \n",
       "..          ...         ...         ...  \n",
       "146         422          53          82  \n",
       "147         939         128         218  \n",
       "148         461         101         141  \n",
       "149         378          52          77  \n",
       "150         340          65          89  \n",
       "\n",
       "[151 rows x 114 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quas = pd.read_excel('Unipark 822.xlsx')\n",
    "quas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d76826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_counter_global</th>\n",
       "      <th>PreNegRe</th>\n",
       "      <th>PreNegRT</th>\n",
       "      <th>PreNeuRe</th>\n",
       "      <th>PreNeuRT</th>\n",
       "      <th>PrePosRe</th>\n",
       "      <th>PrePosRT</th>\n",
       "      <th>PasNegRe</th>\n",
       "      <th>PasNegRT</th>\n",
       "      <th>PasNeuRe</th>\n",
       "      <th>PasNeuRT</th>\n",
       "      <th>PasPosRe</th>\n",
       "      <th>PasPosRT</th>\n",
       "      <th>OthNegRe</th>\n",
       "      <th>OthNegRT</th>\n",
       "      <th>OthNeuRe</th>\n",
       "      <th>OthNeuRT</th>\n",
       "      <th>OthPosRe</th>\n",
       "      <th>OthPosRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1689.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>3510.714286</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3610.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1930.500000</td>\n",
       "      <td>2.66666666666667</td>\n",
       "      <td>1148.33333333333</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3386.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2885.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2288.400000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3212.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26119.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2696.166667</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>1966.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2814.833333</td>\n",
       "      <td>2.16666666666667</td>\n",
       "      <td>2214.66666666667</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2298.000000</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>2415.285714</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2315.333333</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3551.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16135.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>21748.166667</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>21577.857143</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>24843.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>18012.6666666667</td>\n",
       "      <td>4.00</td>\n",
       "      <td>26657.500000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>28219.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>19296.500000</td>\n",
       "      <td>3.75</td>\n",
       "      <td>16065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>12666.600000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>6565.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7323.200000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>6599.250000</td>\n",
       "      <td>3.33333333333333</td>\n",
       "      <td>9722.33333333333</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6679.875000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5432.166667</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>8121.571429</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5592.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>6523.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>5255.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8360.750000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>10971.333333</td>\n",
       "      <td>3.16666666666667</td>\n",
       "      <td>4537.66666666667</td>\n",
       "      <td>4.00</td>\n",
       "      <td>9386.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4527.200000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>5059.600000</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4817.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>408</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>8581.800000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>6075.166667</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>9108.750000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>9449.750000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8361.2</td>\n",
       "      <td>3.50</td>\n",
       "      <td>10243.333333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>5610.666667</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>5717.250000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>411</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4917.333333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2929.142857</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2699.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9452.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3763.75</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4441.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2550.833333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2035.250000</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1894.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>413</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>11423.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>8850.333333</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>7119.750000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>11710.666667</td>\n",
       "      <td>2.66666666666667</td>\n",
       "      <td>5176.66666666667</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10957.666667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>4999.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5107.833333</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5381.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>432</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4038.500000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>2800.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2130.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3648.800000</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2462</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2469.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2255.625000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2774.000000</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2400.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>433</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3243.400000</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>3680.428571</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2825.666667</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3992.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>3936.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3264.625000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>4169.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4612.166667</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3095.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subj_counter_global  PreNegRe      PreNegRT  PreNeuRe      PreNeuRT  \\\n",
       "0                      1  2.000000   1689.000000  2.571429   3510.714286   \n",
       "1                      2  2.000000  26119.000000  2.500000   2696.166667   \n",
       "2                      5  2.000000  16135.000000  3.000000  21748.166667   \n",
       "3                     10  2.400000  12666.600000  3.800000   6565.400000   \n",
       "4                     13  2.428571   6523.428571  3.500000   5255.250000   \n",
       "..                   ...       ...           ...       ...           ...   \n",
       "161                  408  2.400000   8581.800000  3.666667   6075.166667   \n",
       "162                  411  1.333333   4917.333333  2.142857   2929.142857   \n",
       "163                  413  2.800000  11423.400000  2.500000   8850.333333   \n",
       "164                  432  2.500000   4038.500000  2.125000   2800.000000   \n",
       "165                  433  2.000000   3243.400000  2.714286   3680.428571   \n",
       "\n",
       "     PrePosRe      PrePosRT  PasNegRe      PasNegRT          PasNeuRe  \\\n",
       "0    3.000000   3610.000000  2.000000   1930.500000  2.66666666666667   \n",
       "1    3.571429   1966.142857  2.000000   2814.833333  2.16666666666667   \n",
       "2    3.142857  21577.857143  2.500000  24843.250000                 3   \n",
       "3    3.000000   7323.200000  2.250000   6599.250000  3.33333333333333   \n",
       "4    3.000000   8360.750000  2.666667  10971.333333  3.16666666666667   \n",
       "..        ...           ...       ...           ...               ...   \n",
       "161  3.750000   9108.750000  1.750000   9449.750000               3.6   \n",
       "162  3.600000   2699.400000  2.000000   9452.500000               2.5   \n",
       "163  2.750000   7119.750000  2.833333  11710.666667  2.66666666666667   \n",
       "164  3.400000   2130.800000  3.600000   3648.800000               2.8   \n",
       "165  4.000000   2825.666667  2.400000   3992.400000                 2   \n",
       "\n",
       "             PasNeuRT  PasPosRe      PasPosRT  OthNegRe      OthNegRT  \\\n",
       "0    1148.33333333333      3.50   3386.666667  2.166667   2885.333333   \n",
       "1    2214.66666666667      3.00   2298.000000  1.428571   2415.285714   \n",
       "2    18012.6666666667      4.00  26657.500000  2.600000  28219.000000   \n",
       "3    9722.33333333333      3.50   6679.875000  2.000000   5432.166667   \n",
       "4    4537.66666666667      4.00   9386.333333  2.000000   4527.200000   \n",
       "..                ...       ...           ...       ...           ...   \n",
       "161            8361.2      3.50  10243.333333  1.166667   5610.666667   \n",
       "162           3763.75      3.00   4441.600000  1.000000   2550.833333   \n",
       "163  5176.66666666667      2.00  10957.666667  2.250000   4999.500000   \n",
       "164              2462      3.00   2469.000000  1.250000   2255.625000   \n",
       "165            3936.5      3.25   3264.625000  2.600000   4169.800000   \n",
       "\n",
       "     OthNeuRe      OthNeuRT  OthPosRe  OthPosRT  \n",
       "0    3.000000   2288.400000      3.00    3212.5  \n",
       "1    2.666667   2315.333333      3.20    3551.2  \n",
       "2    3.333333  19296.500000      3.75   16065.0  \n",
       "3    3.428571   8121.571429      5.00    5592.5  \n",
       "4    2.600000   5059.600000      4.20    4817.4  \n",
       "..        ...           ...       ...       ...  \n",
       "161  1.750000   5717.250000      4.00    5677.0  \n",
       "162  2.000000   2035.250000      2.80    1894.4  \n",
       "163  2.666667   5107.833333      3.80    5381.2  \n",
       "164  2.000000   2774.000000      3.80    2400.4  \n",
       "165  2.000000   4612.166667      3.50    3095.0  \n",
       "\n",
       "[166 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encod = pd.read_csv('EncodingAggregated (1).csv')\n",
    "encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c3ef921",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalAnswer_Ecncoding = ans.merge(encod, left_on='Nosub', right_on='subj_counter_global', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ace07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalAnswer_Ecncoding_questionnaire = recalAnswer_Ecncoding.merge(quas, left_on='VPCode', right_on='VPCode', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fc4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenset = pd.read_csv('Datenset0406 (3) CSV.csv', sep=';')\n",
    "# VPCode = Datenset['VPCode']\n",
    "# Datenset = Datenset.iloc[:,8:17]\n",
    "# Datenset['VPCode'] = VPCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "456946db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalAnswer_Ecncoding_questionnaire = recalAnswer_Ecncoding_questionnaire.merge(Datenset, left_on='VPCode',\n",
    "#                                                                                 right_on='VPCode', how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc487bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"this method is only for help and evaluates the output depending on whether the data\n",
    " needs to be turned over or not\"\"\"\n",
    "def evaluate_psychological(self, i, colums, name, dataset, teilen):\n",
    "    if teilen :\n",
    "        sum = 0\n",
    "        for j in colums:\n",
    "            if int(colums.__getitem__(j)) == 0:\n",
    "               # has not to be inverted\n",
    "               sum += int(dataset[j][i])\n",
    "\n",
    "            elif int(colums.__getitem__(j)) == 1:\n",
    "                # has to be inverted\n",
    "                value = int(dataset[j][i])\n",
    "                if value == 1:\n",
    "                    sum += 6\n",
    "                elif value == 2:\n",
    "                    sum += 5\n",
    "                elif value == 3:\n",
    "                    sum += 4\n",
    "                elif value == 4:\n",
    "                    sum += 3\n",
    "                elif value == 5:\n",
    "                    sum += 2\n",
    "                elif value == 6:\n",
    "                    sum += 1\n",
    "\n",
    "        sum = sum / colums.__len__()\n",
    "        dataset[name][i] = sum.__round__(2)\n",
    "\n",
    "       # dataset.insert(i, name, sum)\n",
    "    else:\n",
    "        sum = 0\n",
    "        for j in colums:\n",
    "            if int(colums.__getitem__(j)) == 0:\n",
    "               # has not to be inverted\n",
    "               sum += int(dataset[j][i])\n",
    "\n",
    "            elif int(colums.__getitem__(j)) == 1:\n",
    "                # has to be inverted\n",
    "                value = int(dataset[j][i])\n",
    "                if value == 1:\n",
    "                    sum += 6\n",
    "                elif value == 2:\n",
    "                    sum += 5\n",
    "                elif value == 3:\n",
    "                    sum += 4\n",
    "                elif value == 4:\n",
    "                    sum += 3\n",
    "                elif value == 5:\n",
    "                    sum += 2\n",
    "                elif value == 6:\n",
    "                    sum += 1\n",
    "\n",
    "        return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b51a758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start  insert_psychological_wellbeing\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m Pb \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_26\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_30\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_35\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv_72\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     81\u001b[0m         }\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, count_rows):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mevaluate_psychological(i, K, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK_Mittelwert\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_psychological(i, Pw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPW_Mittelwert\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_psychological(i, SL, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSL_Mittelwert\u001b[39m\u001b[38;5;124m'\u001b[39m, dataset, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "############################################### Unipark data evaluation###################################\n",
    "##########################################################################################################\n",
    "##########################################################################################################\n",
    "\n",
    "\"\"\"this method inserts values such as KW, PW mean value, ... into the Unipark data table a\"\"\"\n",
    "print(\"start  insert_psychological_wellbeing\")\n",
    "\n",
    "dataset = recalAnswer_Ecncoding_questionnaire.copy()\n",
    "\n",
    "count_rows = dataset.shape[0]\n",
    "\n",
    "column_names = ['K_Mittelwert', 'PW_Mittelwert', 'SL_Mittelwert', 'A_Mittelwert', 'SA_Mittelwert',\n",
    "                'PB_Mittelwert', 'PWB_Mittelwert']\n",
    "for i in column_names:\n",
    "    dataset[i] = 0.00\n",
    "\n",
    "K = {  'v_27': 0,\n",
    "        'v_32': 1,\n",
    "        'v_37': 1,\n",
    "        'v_42': 0,\n",
    "        'v_45': 1,\n",
    "        'v_54': 0,\n",
    "        'v_61': 0,\n",
    "        'v_74': 1,\n",
    "        'v_78': 0\n",
    "        }\n",
    "\n",
    "Pw = {  'v_28': 1,\n",
    "        'v_43': 1,\n",
    "        'v_46': 0,\n",
    "        'v_51': 1,\n",
    "        'v_62': 0,\n",
    "        'v_66': 1,\n",
    "        'v_75': 1,\n",
    "        'v_79': 1\n",
    "        }\n",
    "\n",
    "SL = {  'v_33': 1,\n",
    "        'v_38': 1,\n",
    "        'v_47': 1,\n",
    "        'v_52': 1,\n",
    "        'v_55': 1,\n",
    "        'v_58': 0,\n",
    "        'v_63': 0,\n",
    "        'v_67': 0,\n",
    "        'v_71': 1\n",
    "        }\n",
    "\n",
    "A = {  'v_31': 0,\n",
    "        'v_36': 0,\n",
    "        'v_41': 1,\n",
    "        'v_44': 0,\n",
    "        'v_50': 1,\n",
    "        'v_60': 0,\n",
    "        'v_65': 1,\n",
    "        'v_69': 1,\n",
    "        'v_77': 0\n",
    "        }\n",
    "\n",
    "SA = {  'v_29': 0,\n",
    "        'v_34': 0,\n",
    "        'v_39': 1,\n",
    "        'v_48': 0,\n",
    "        'v_53': 0,\n",
    "        'v_56': 1,\n",
    "        'v_68': 1,\n",
    "        'v_70': 0,\n",
    "        'v_73': 0,\n",
    "        'v_76': 0\n",
    "        }\n",
    "\n",
    "Pb = {  'v_26': 0,\n",
    "        'v_30': 1,\n",
    "        'v_35': 1,\n",
    "        'v_40': 0,\n",
    "        'v_49': 1,\n",
    "        'v_57': 1,\n",
    "        'v_59': 0,\n",
    "        'v_64': 1,\n",
    "        'v_72': 0\n",
    "        }\n",
    "\n",
    "for i in range(0, count_rows):\n",
    "    evaluate_psychological(i, K, 'K_Mittelwert', dataset, True)\n",
    "    evaluate_psychological(i, Pw, 'PW_Mittelwert', dataset, True)\n",
    "    evaluate_psychological(i, SL, 'SL_Mittelwert', dataset, True)\n",
    "    evaluate_psychological(i, A, 'A_Mittelwert', dataset, True)\n",
    "    evaluate_psychological(i, SA, 'SA_Mittelwert', dataset, True)\n",
    "    evaluate_psychological(i, Pb, 'PB_Mittelwert', dataset, True)\n",
    "\n",
    "    dataset['PWB_Mittelwert'][i] = (evaluate_psychological(i, K, 'K_Mittelwert', dataset, False) +\\\n",
    "                                    evaluate_psychological(i, K, 'PW_Mittelwert', dataset, False)\\\n",
    "                                   + evaluate_psychological(i, K, 'SL_Mittelwert', dataset, False) +\\\n",
    "                                    evaluate_psychological(i, K, 'A_Mittelwert', dataset, False) \\\n",
    "                                   + evaluate_psychological(i, K, 'SA_Mittelwert', dataset, False) + \\\n",
    "                                    evaluate_psychological(i, K, 'PB_Mittelwert', dataset, False)) / 54\n",
    "    dataset.to_csv('recalAnswer_Ecncoding_questionnaire with Mittelwert',\n",
    "                   index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa693c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"that method evaluates self_esteem\"\"\"\n",
    "def self_esteem(self):\n",
    "    print(\"start  self_esteem\")\n",
    "    dataset = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "    count_rows = dataset.shape[0]\n",
    "    dataset['self_esteem'] = 0\n",
    "    se = {  'v_80': 0,\n",
    "            'v_81': 1,\n",
    "            'v_82': 0,\n",
    "            'v_83': 0,\n",
    "            'v_84': 1,\n",
    "            'v_85': 1,\n",
    "            'v_86': 0,\n",
    "            'v_87': 1,\n",
    "            'v_88': 1,\n",
    "            'v_89': 0\n",
    "            }\n",
    "    for i in range(count_rows):\n",
    "        sum = 0\n",
    "        for j in se:\n",
    "            if int(se.__getitem__(j)) == 0:\n",
    "                # has not to be inverted\n",
    "                sum += int(dataset[j][i])\n",
    "\n",
    "            elif int(se.__getitem__(j)) == 1:\n",
    "                # has to be inverted\n",
    "                value = int(dataset[j][i])\n",
    "                if value == 1:\n",
    "                    sum += 4\n",
    "                elif value == 2:\n",
    "                    sum += 3\n",
    "                elif value == 3:\n",
    "                    sum += 2\n",
    "                elif value == 4:\n",
    "                    sum += 1\n",
    "\n",
    "        dataset['self_esteem'][i] = sum.__round__(2)\n",
    "\n",
    "    dataset.to_csv(self.second_path_lower, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "\"\"\"that method evaluates psycologic_wellbeing\"\"\"\n",
    "def social_psycologic_wellbeing(self):\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "    print(\"start  social_psycologic_wellbeing\")\n",
    "    sum = 0\n",
    "    dataset = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "    count_rows = dataset.shape[0]\n",
    "    dataset['social_psycologic_wellbeing'] = 0\n",
    "    se = ['v_90', 'v_91', 'v_92', 'v_93', 'v_94', 'v_95', 'v_96', 'v_97']\n",
    "    for i in range(count_rows):\n",
    "        sum = 0\n",
    "        for j in se:\n",
    "            sum += int(dataset[j][i])\n",
    "\n",
    "        dataset['social_psycologic_wellbeing'][i] = sum\n",
    "    dataset.to_csv(self.second_path_lower, index=False, sep=';', float_format='%.3f', decimal='.', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"here you import the necessary libarys to install them write in cmd 'pip istall pandas' and 'pip insatll numpy\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "class csv_Handler(object):\n",
    "\n",
    "    \"\"\"please adjust the path to the tables and the table names \"\"\"\n",
    "    \"\"\"this method is used to initialize the paths to the tables\"\"\"\n",
    "    def __init__(self):\n",
    "        pd.set_option('mode.chained_assignment', None)\n",
    "        self.main_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\\\Sara_Master\\\\LD.csv\"\n",
    "        self.second_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\Sara_Master\\\\UD.csv\"\n",
    "        self.adj_path = \"C:\\\\Users\\\\User\\\\Desktop\\\\Sara_Master\\\\Adjectives_masterfile.csv\"\n",
    "\n",
    "        self.main_path_lower = \"C:\\\\Users\\\\User\\\\Desktop\\\\Sara_Master\\\\LD_lower.csv\"\n",
    "        self.second_path_lower = \"C:\\\\Users\\\\User\\\\Desktop\\\\Sara_Master\\\\UD_lower.csv\"\n",
    "        self.pre_past_other = \"C:\\\\Users\\\\User\\\\Desktop\\\\Sara_Master\\\\pre_past_other_valenz.csv\"\n",
    "\n",
    "\n",
    "        self.VPCodeIndex = self.get_column_index(self.second_path, 'VPCode')\n",
    "        self.PartCodeIndex = self.get_column_index(self.main_path, 'ParticipantCode')\n",
    "\n",
    "    \"\"\"this method is only to help you check if data objects are nan\"\"\"\n",
    "    def is_nan(self, x):\n",
    "        return x is np.nan or x != x\n",
    "\n",
    "    \"\"\"this method returns the index of the column of the passed name and table \"\"\"\n",
    "    def get_column_index(self, path, column):\n",
    "        index = 0\n",
    "        dataset = pd.read_csv(path, sep=';')\n",
    "        columns = dataset.columns.tolist()\n",
    "        for i in columns:\n",
    "            if i == column:\n",
    "                return index\n",
    "            else:\n",
    "                index += 1\n",
    "\n",
    "    ########################################################################################################\n",
    "    #######################################Clean Tabel######################################################\n",
    "\n",
    "    \"\"\"this method goes through each row for each column until it finds a non-empty entry,\n",
    "       if all fields are empty the column is deleted from the table \"\"\"\n",
    "    def delete_empty_column(self):\n",
    "        dataset = pd.read_csv(self.main_path, sep=';')\n",
    "        # get collums\n",
    "        columns = dataset.columns.tolist()\n",
    "\n",
    "        # for each column of the table\n",
    "        keep_coll = []\n",
    "        for i in columns:\n",
    "            column_values = dataset[i]\n",
    "\n",
    "            # for each row of one column\n",
    "            for j in column_values:\n",
    "                # if it is not Nan add it to the list of columns which should be preserved to\n",
    "                if not self.is_nan(j) and j is not None and j != '\\n' and j != '\\t' and j != ' ':\n",
    "                    keep_coll.append(i)\n",
    "                    break\n",
    "\n",
    "        # make new csv with same name and other columns\n",
    "        new_dataset = dataset[keep_coll]\n",
    "        new_dataset.to_csv(self.main_path, index=False, sep=';')\n",
    "        print(\"deleted all unused columns\")\n",
    "\n",
    "    \"\"\"this method returns the row to the respective VPCode of the UniparkData table\"\"\"\n",
    "    def get_row_second_Table(self, name):\n",
    "        try:\n",
    "            df = pd.read_csv(self.second_path_lower, sep=';')\n",
    "            df2 = df.set_index(\"VPCode\", drop=False)\n",
    "            return df2.loc[name, :]\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    \"\"\"This tasbelle inserts the UniparkData table into the Labvanced table\"\"\"\n",
    "    def merge(self):\n",
    "        # make all codes to lowercase\n",
    "        self.make_lowercase()\n",
    "        global other_Table_row\n",
    "        # read the tables\n",
    "        table2 = pd.read_csv(self.second_path_lower, sep=';')\n",
    "        columns_table2 = table2.columns.tolist()\n",
    "        table1 = pd.read_csv(self.main_path_lower, sep=';')\n",
    "        # append the new columns\n",
    "        for i in columns_table2:\n",
    "            if i != 'VPCode':\n",
    "                table1[i] = \"\"\n",
    "        # write new columns to csv\n",
    "        table1.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "\n",
    "        # go through all lines\n",
    "        count_rows = table1.shape[0]\n",
    "        for i in range(0, count_rows):\n",
    "            # get the row from original Table\n",
    "            row = table1.loc[i, :]\n",
    "            # if the value is not None or NaN, get the correct row from the other Table\n",
    "\n",
    "            if row[self.PartCodeIndex] is not None and not self.is_nan(row[self.PartCodeIndex]) and row[self.PartCodeIndex] != ' ' and row[self.PartCodeIndex] != '':\n",
    "                other_Table_row = self.get_row_second_Table(row[self.PartCodeIndex])\n",
    "\n",
    "                if other_Table_row is False:\n",
    "                    pass\n",
    "\n",
    "                help = 0\n",
    "                # insert the new columns\n",
    "                for c in columns_table2:\n",
    "                    try:\n",
    "                        table1._set_value(i, c, other_Table_row[help])\n",
    "                        help += 1\n",
    "                    except:\n",
    "                        break\n",
    "\n",
    "        # overwrite the new csv file\n",
    "        table1.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "        print(\"Merged Tables\")\n",
    "\n",
    "    \"\"\"this method helps to make the VPCode tidier, because sometimes upper and lower\n",
    "     case letters and special characters have been swapped\"\"\"\n",
    "    def make_lowercase(self):\n",
    "        # secound Table\n",
    "        # get the Table\n",
    "        table2 = pd.read_csv(self.second_path, sep=';')\n",
    "        count_rows = table2.shape[0]\n",
    "\n",
    "        # go through the lines\n",
    "        for i in range(0, count_rows):\n",
    "            row = table2.loc[i, :]\n",
    "            code_list = list(row[self.VPCodeIndex].lower())\n",
    "            code = \"\"\n",
    "            for c in code_list:\n",
    "                if c == \"a\" or c == \"b\" or c == \"c\" or c == \"d\" or c == \"e\" or c == \"f\" or c == \"g\" \\\n",
    "                        or c == \"h\" or c == \"i\" or c == \"j\" or c == \"k\" or c == \"l\" or c == \"m\" or c == \"n\" \\\n",
    "                        or c == \"o\" or c == \"p\" or c == \"q\" or c == \"r\" or c == \"s\" or c == \"t\" or c == \"u\" \\\n",
    "                        or c == \"v\" or c == \"w\" or c == \"x\" or c == \"y\" or c == \"z\" or c == \"1\" or c == \"2\" \\\n",
    "                        or c == \"3\" or c == \"4\" or c == \"5\" or c == \"6\" or c == \"7\" or c == \"8\" or c == \"9\" \\\n",
    "                        or c == \"0\" or c == \"ß\" or c == \"\" or c == \"b\" or c == \"b\" or c == \"b\":\n",
    "                    code += c\n",
    "\n",
    "            table2._set_value(i, \"VPCode\", code)\n",
    "        table2.to_csv(self.second_path_lower, index=False, sep=';')\n",
    "\n",
    "        # main Table+\n",
    "        # get the Table\n",
    "        table1 = pd.read_csv(self.main_path, sep=';')\n",
    "        count_rows = table1.shape[0]\n",
    "\n",
    "        # go through the lines\n",
    "        for i in range(0, count_rows):\n",
    "            row = table1.loc[i, :]\n",
    "            if not self.is_nan(row[self.PartCodeIndex]):\n",
    "                code_list = list(row[self.PartCodeIndex].lower())\n",
    "                code = \"\"\n",
    "                for c in code_list:\n",
    "                    if c == \"a\" or c == \"b\" or c == \"c\" or c == \"d\" or c == \"e\" or c == \"f\" or c == \"g\" \\\n",
    "                            or c == \"h\" or c == \"i\" or c == \"j\" or c == \"k\" or c == \"l\" or c == \"m\" or c == \"n\" \\\n",
    "                            or c == \"o\" or c == \"p\" or c == \"q\" or c == \"r\" or c == \"s\" or c == \"t\" or c == \"u\" \\\n",
    "                            or c == \"v\" or c == \"w\" or c == \"x\" or c == \"y\" or c == \"z\" or c == \"1\" or c == \"2\" \\\n",
    "                            or c == \"3\" or c == \"4\" or c == \"5\" or c == \"6\" or c == \"7\" or c == \"8\" or c == \"9\" \\\n",
    "                            or c == \"0\" or c == \"ß\" or c == \"\" or c == \"b\" or c == \"b\" or c == \"b\":\n",
    "                        code += c\n",
    "                table1._set_value(i, \"ParticipantCode\", code)\n",
    "\n",
    "        table1.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "        print(\"all codes to Lowercase\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##########################################################################################################\n",
    "    ##################################################Data Evaluation ########################################\n",
    "\n",
    "    \"\"\"this method is only a help to evaluate Which case occurred,\n",
    "     whether the word was mentioned in encode or not, and which answer was given, \n",
    "     is put into practice and given an index from 0 to 5\"\"\"\n",
    "    def evaluate_output(self, guess, trial_Ids, trial_Id):\n",
    "        # evaluate output\n",
    "        in_encode = False\n",
    "        for i in trial_Ids:\n",
    "            if int(i) == int(float(trial_Id)):\n",
    "                in_encode = True\n",
    "\n",
    "        if in_encode:\n",
    "            #Wort wurde genannt\n",
    "\n",
    "            if int(float(guess)) == 0:\n",
    "                return 0\n",
    "            elif int(float(guess)) == 1:\n",
    "                return 1\n",
    "            elif int(float(guess)) == 2:\n",
    "                return 2\n",
    "\n",
    "        else:\n",
    "            #Wort wurde nicht genannt\n",
    "            if int(float(guess)) == 0:\n",
    "                return 3\n",
    "            elif int(float(guess)) == 1:\n",
    "                return 4\n",
    "            elif int(float(guess)) == 2:\n",
    "                return 5\n",
    "\n",
    "        # 1, 2, 3\n",
    "\n",
    "    \"\"\"this method inserts a column in the table in which, depending on \n",
    "    the evaluation whether the adjective already existed or it is new and depending on \n",
    "    what was said by the respondent, the numbers 0, 1, 2, 3 are inserted at the level of recognition \"\"\"\n",
    "\n",
    "    def insert_recognition_evaluation(self, name= \"recognition_evaluation\"):\n",
    "        print(\"start insert recognition evaluation test\")\n",
    "        # get tabel and append new column\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';',dtype='unicode')\n",
    "        dataset[name] = \"\"\n",
    "        # get the number of columns\n",
    "        count_rows = dataset.shape[0]\n",
    "        # make list and dir to save values\n",
    "        trial_Ids = []\n",
    "        dict_ID_TrtialIDs = {}\n",
    "        # save the last and the old id \"subje_ctcounter\"\n",
    "        old_id = 0\n",
    "        last_id=dataset['subj_counter_global'][count_rows-1]\n",
    "        # just in time to get the end of the last section\n",
    "        count_last = 0\n",
    "        # go through all rows\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            # get the id of the row\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            # if the BlockName end with encode\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"encode\"):\n",
    "\n",
    "                \"\"\"for each line check if it is not the last id, if not, append the values to the list until the id changes.\n",
    "                    if the id changes add this list and the corresponding id to the dict. If the id is the last id, \n",
    "                    add the previous list to dict. and continue adding values to the list until counter 44 is reached\"\"\"\n",
    "\n",
    "                if id != last_id:\n",
    "                    if id != old_id:\n",
    "                        if old_id != 0:\n",
    "                            dict_ID_TrtialIDs.update({int(float(old_id)) : trial_Ids})\n",
    "\n",
    "                        trial_Ids = []\n",
    "\n",
    "                        trial_Ids.append(int(float(dataset['Trial_Id'][i])))\n",
    "                        old_id = id\n",
    "                    else:\n",
    "                        trial_Ids.append(int(float(dataset['Trial_Id'][i])))\n",
    "                        old_id = id\n",
    "                else:\n",
    "                    count_last += 1\n",
    "                    if id != old_id:\n",
    "\n",
    "                        dict_ID_TrtialIDs.update({int(float(old_id)): trial_Ids})\n",
    "                        trial_Ids = []\n",
    "                        trial_Ids.append(int(float(dataset['Trial_Id'][i])))\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last != 44:\n",
    "                        trial_Ids.append(int(float(dataset['Trial_Id'][i])))\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last == 44:\n",
    "                        dict_ID_TrtialIDs.update({int(float(id)): trial_Ids})\n",
    "\n",
    "\n",
    "        #go through the table one more time\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            # if the BlockName end with recognition\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and\\\n",
    "                    dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "\n",
    "                if not self.is_nan(dataset['subj_counter_global'][i]) and dataset['subj_counter_global'][i] != \"\" and\\\n",
    "                        dataset['subj_counter_global'][i] != \" \" and dataset['subj_counter_global'][i] != None:\n",
    "\n",
    "                    \"\"\"get the appropriate list from the dict. to see if the Triaal id has been used before.\n",
    "                     Try catch, as it is possible that there may be entries for recognition of a person but not for encode\"\"\"\n",
    "\n",
    "                    try:\n",
    "                        trial_Id_List = dict_ID_TrtialIDs[int(float(dataset['subj_counter_global'][i]))]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    #get values to evaluate the output\n",
    "                    guess = dataset['RemKnoGue_55'][i]\n",
    "                    trial_Id = dataset['Trial_Id'][i]\n",
    "\n",
    "                    # evaluate the result of recognition and write it in the new column\n",
    "                    evaluate = self.evaluate_output(guess, trial_Id_List, trial_Id)\n",
    "                    dataset._set_value(i, name, evaluate)\n",
    "\n",
    "\n",
    "        dataset.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "\n",
    "    \"\"\"this method returns the valence of the adjective in the list adj,\n",
    "     which is identified by the sub number and the list in which it appears 1 or 2\"\"\"\n",
    "    def get_Valenz(self, liste, subNummer, adj):\n",
    "\n",
    "        ka = 88\n",
    "        for i in adj:\n",
    "            t = adj.__getitem__(i)\n",
    "\n",
    "            if t[0] == int(liste) and t[1] == int(float(subNummer)):\n",
    "                ka = t[2]\n",
    "        return ka\n",
    "\n",
    "    \"\"\"this method is only to help fill the dictonary which caches the values\n",
    "     for each adjective with the new values  \"\"\"\n",
    "    def update_dict_trial(self, dic_trial_value, i, dataset, liste, adj):\n",
    "\n",
    "        subNummer = dataset['Trial_Nr'][i]\n",
    "        valenz = self.get_Valenz(liste, subNummer, adj)\n",
    "        values = []\n",
    "        #print(str(subNummer) + \"   \" + str(liste)+ \" \" + str(valenz))\n",
    "        values.append(valenz)\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['02_factor_Pas-Oth-Pre'][i]) and dataset['02_factor_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['02_factor_Pas-Oth-Pre'][i] != \"\" and dataset['02_factor_Pas-Oth-Pre'][i] != \" \":\n",
    "            values.append(dataset['02_factor_Pas-Oth-Pre'][i])\n",
    "\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Pr_Pa_Oth'][i]) and dataset['factor02_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['factor02_Pr_Pa_Oth'][i] != \"\" and dataset['factor02_Pr_Pa_Oth'][i] != \" \":\n",
    "            values.append(dataset['factor02_Pr_Pa_Oth'][i])\n",
    "\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Oth-Pre-Pas'][i]) and dataset['factor02_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['factor02_Oth-Pre-Pas'][i] != \"\" and dataset['factor02_Oth-Pre-Pas'][i] != \" \":\n",
    "            values.append(dataset['factor02_Oth-Pre-Pas'][i])\n",
    "\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['factor1_Pr_Pa_Oth_55'][i]) and dataset['factor1_Pr_Pa_Oth_55'][i] != None and \\\n",
    "                dataset['factor1_Pr_Pa_Oth_55'][i] != \"\" and dataset['factor1_Pr_Pa_Oth_55'][i] != \" \":\n",
    "            values.append(dataset['factor1_Pr_Pa_Oth_55'][i])\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['factor2_Oth_Pre_Pas_55'][i]) and dataset['factor2_Oth_Pre_Pas_55'][i] != None and \\\n",
    "                dataset['factor2_Oth_Pre_Pas_55'][i] != \"\" and dataset['factor2_Oth_Pre_Pas_55'][i] != \" \":\n",
    "            values.append(dataset['factor2_Oth_Pre_Pas_55'][i])\n",
    "\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['factor3_Pas-Oth-Pre'][i]) and dataset['factor3_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['factor3_Pas-Oth-Pre'][i] != \"\" and dataset['factor3_Pas-Oth-Pre'][i] != \" \":\n",
    "            values.append(dataset['factor3_Pas-Oth-Pre'][i])\n",
    "\n",
    "            dic_trial_value.update({int(float(dataset['Trial_Id'][i])): values})\n",
    "            return dic_trial_value\n",
    "\n",
    "    \"\"\"this method returns the list in which the adjective is located\"\"\"\n",
    "    def get_Liste_for_adj(self, i , dataset):\n",
    "\n",
    "        column = ['02_Readout_Oth-Pre-Pas_0', '02_Readout_Pas-Oth-Pre_0', '02_Readout_Pre-Pas-Oth', 'Readout_Oth_Pre_Pas_55', 'Readout_Pas-Oth-Pre_0', 'Readout_Pr_Pa_Oth_55']\n",
    "        for c in column:\n",
    "            if dataset[c][i] == 'depressiv':\n",
    "                return 1\n",
    "            elif dataset[c][i] == 'pessimistisch' or dataset[c][i] == 'behindert':\n",
    "                return 2\n",
    "\n",
    "    \"\"\"this method creates a csv file if none exists and inserts how many adjectives of \n",
    "    Present Past or other with which valence have been correctly recognized by the test person\"\"\"\n",
    "    def evaluate_past_present_other_test_with_valenz(self):\n",
    "        global value_list\n",
    "        print(\"start  evaluate_past_present_other_test_with valenz\")\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "\n",
    "        count = 0  # um zu zelehn wie oft rcognition aufgerufen wurde\n",
    "        help = False  # um zu gucken ob schon eine csv erstellt wurde\n",
    "        file = Path(self.pre_past_other)\n",
    "        if file.is_file():\n",
    "            print(\"csv schon erstellt\")\n",
    "            help = True\n",
    "        dic_id_dict = {}\n",
    "        dic_trial_value ={}\n",
    "\n",
    "        adj = self.get_adj_as_dict()\n",
    "        #count variablen\n",
    "\n",
    "        pres_pos = 0\n",
    "        pres_neu = 0\n",
    "        pres_neg = 0\n",
    "        past_pos = 0\n",
    "        past_neu = 0\n",
    "        past_neg = 0\n",
    "        oth_pos = 0\n",
    "        oth_neu = 0\n",
    "        oth_neg = 0\n",
    "        notShown = 0\n",
    "\n",
    "        #zeile der erstellten csv\n",
    "        x = 0\n",
    "        # for encode\n",
    "        old_id = 0\n",
    "        last_id = dataset['subj_counter_global'][count_rows - 1]\n",
    "        count_last = 0\n",
    "\n",
    "        #new values\n",
    "        liste = 1\n",
    "        # go through the lines\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"encode\"):\n",
    "\n",
    "                if id != last_id:\n",
    "\n",
    "                    if id != old_id:\n",
    "\n",
    "                        if old_id != 0:\n",
    "                            dic_id_dict.update({int(float(old_id)): dic_trial_value})\n",
    "\n",
    "                        # quasi der naechste Anfang von encode...\n",
    "\n",
    "                        liste = self.get_Liste_for_adj(i, dataset)\n",
    "                        dic_trial_value = {}\n",
    "\n",
    "\n",
    "                        help_dic = dic_trial_value.copy()\n",
    "                        dic_trial_value = self.update_dict_trial(help_dic, i, dataset, liste, adj)\n",
    "                        old_id = id\n",
    "\n",
    "                    else:\n",
    "                        help_dic = dic_trial_value.copy()\n",
    "                        dic_trial_value = self.update_dict_trial(help_dic, i, dataset, liste, adj)\n",
    "                        old_id = id\n",
    "\n",
    "                else:\n",
    "                    count_last += 1\n",
    "                    if id != old_id:\n",
    "\n",
    "                        dic_id_dict.update({int(float(old_id)): dic_trial_value})\n",
    "                        help_dic = dic_trial_value.copy()\n",
    "                        dic_trial_value = self.update_dict_trial(dic_trial_value, i, dataset, liste, adj)\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last != 44:\n",
    "                        help_dic = dic_trial_value.copy()\n",
    "                        dic_trial_value = self.update_dict_trial(dic_trial_value, i, dataset, liste, adj)\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last == 44:\n",
    "                        dic_id_dict.update({int(float(id)): dic_trial_value})\n",
    "\n",
    "        print(str(dic_id_dict))\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "                id = dataset['subj_counter_global'][i]\n",
    "\n",
    "                try:\n",
    "                    if self.is_nan(id):\n",
    "                        id = dataset['subj_counter_global'][i+3]\n",
    "\n",
    "                    id_factor_dic = dic_id_dict[int(float(id))]\n",
    "\n",
    "                    # wenn quasi die richtige antwort gegeben wurde\n",
    "                    if dataset['recognition_evaluation'][i] == '1' or dataset['recognition_evaluation'][i] == '2' or \\\n",
    "                            dataset['recognition_evaluation'][i] == '3' or dataset['recognition_evaluation'][i] == 1 or \\\n",
    "                            dataset['recognition_evaluation'][i] == 3 or dataset['recognition_evaluation'][i] == 3:\n",
    "\n",
    "                        try:\n",
    "                            value_list = id_factor_dic[int(float(dataset['Trial_Id'][i]))]\n",
    "\n",
    "                            if value_list[0] == 1:\n",
    "                                # positiv\n",
    "                                if value_list[1] == 'Past' or value_list[1] == 'past':\n",
    "                                    past_pos += 1\n",
    "                                elif value_list[1] == 'Present' or value_list[1] == 'present':\n",
    "                                    pres_pos += 1\n",
    "                                elif value_list[1] == 'other' or value_list[1] == 'Other':\n",
    "                                    oth_pos += 1\n",
    "\n",
    "                            elif value_list[0] == 0:\n",
    "                                # neutal\n",
    "                                if value_list[1] == 'Past' or value_list[1] == 'past':\n",
    "                                    past_neu += 1\n",
    "                                elif value_list[1] == 'Present' or value_list[1] == 'present':\n",
    "                                    pres_neu += 1\n",
    "                                elif value_list[1] == 'other' or value_list[1] == 'Other':\n",
    "                                    oth_neu += 1\n",
    "\n",
    "                            elif value_list[0] == -1:\n",
    "                                if value_list[1] == 'Past' or value_list[1] == 'past':\n",
    "                                    past_neg += 1\n",
    "                                elif value_list[1] == 'Present' or value_list[1] == 'present':\n",
    "                                    pres_neg += 1\n",
    "                                elif value_list[1] == 'other' or value_list[1] == 'Other':\n",
    "                                    oth_neg += 1\n",
    "\n",
    "                        except:\n",
    "                            notShown += 1\n",
    "\n",
    "                    count += 1\n",
    "                    if count == 90:\n",
    "                        if not help:\n",
    "                            id = dataset['subj_counter_global'][i]\n",
    "                            data = {'id': [id],\n",
    "                                    'present_positiv': [pres_pos],\n",
    "                                    'present_negativ': [pres_neg],\n",
    "                                    'present_neutral': [pres_neu],\n",
    "                                    'past_positiv': [past_pos],\n",
    "                                    'past_negativ': [past_neg],\n",
    "                                    'past_neutral': [past_neu],\n",
    "                                    'other_positiv': [oth_pos],\n",
    "                                    'other_negativ': [oth_neg],\n",
    "                                    'other_neutral': [oth_neu],\n",
    "                                    'notShown': [notShown]\n",
    "                                    }\n",
    "                            df = pd.DataFrame(data, columns=['id', 'present_positiv', 'present_negativ', 'present_neutral', 'past_positiv', 'past_negativ', 'past_neutral', 'other_positiv', 'other_negativ', 'other_neutral', 'notShown'])\n",
    "                            df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                            help = True\n",
    "                            x += 1\n",
    "                        else:\n",
    "\n",
    "                            id = dataset['subj_counter_global'][i]\n",
    "                            df = pd.read_csv(self.pre_past_other, sep=';', dtype='unicode')\n",
    "                            df._set_value(x, \"id\", id)\n",
    "                            df._set_value(x, \"present_positiv\", pres_pos)\n",
    "                            df._set_value(x, \"present_negativ\", pres_neg)\n",
    "                            df._set_value(x, \"present_neutral\", pres_neu)\n",
    "                            df._set_value(x, \"past_positiv\", past_pos)\n",
    "                            df._set_value(x, \"past_negativ\", past_neg)\n",
    "                            df._set_value(x, \"past_neutral\", past_neu)\n",
    "                            df._set_value(x, \"other_positiv\", oth_pos)\n",
    "                            df._set_value(x, \"other_negativ\", oth_neg)\n",
    "                            df._set_value(x, \"other_neutral\", oth_neu)\n",
    "                            df._set_value(x, \"notShown\", notShown)\n",
    "\n",
    "                            df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                            x += 1\n",
    "\n",
    "                        count = 0\n",
    "                        pres_pos = 0\n",
    "                        pres_neu = 0\n",
    "                        pres_neg = 0\n",
    "                        past_pos = 0\n",
    "                        past_neu = 0\n",
    "                        past_neg = 0\n",
    "                        oth_pos = 0\n",
    "                        oth_neu = 0\n",
    "                        oth_neg = 0\n",
    "                        notShown = 0\n",
    "\n",
    "                except KeyError:\n",
    "                    ka = 0 #für ids die nicht gefunden wurden\n",
    "\n",
    "    \"\"\"this method returns the table of adjectives as dictionary\"\"\"\n",
    "    def get_adj_as_dict(self, manipul=0):\n",
    "        dataset = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        table_adj = {}\n",
    "        for i in range(0, count_rows):\n",
    "            id = dataset['Nr'][i]\n",
    "            if manipul== 0:\n",
    "                table_adj.update({int(id): [int(dataset['Liste'][i]), int(dataset['Subnumber'][i]), int(dataset['Valenz'][i])]})\n",
    "            else:\n",
    "                table_adj.update({dataset['Adjektiv'][i]: [0, 0]})\n",
    "        print(table_adj)\n",
    "        return table_adj\n",
    "\n",
    "    \"\"\"this method inserts the values in the table of results,\n",
    "     ...which, according to index 0, 1, 2... FP, CF, CR,... were named correct / incorrect\"\"\"\n",
    "    def special_data_requests(self, index=1):\n",
    "        name = \"\"\n",
    "        if index == 0:\n",
    "            name = \"FP\"\n",
    "        elif index == 1:\n",
    "            name = \"CF\"\n",
    "        elif index == 2:\n",
    "            name = \"CR\"\n",
    "        elif index == 3:\n",
    "            name = \"CN\"\n",
    "        elif index == 4:\n",
    "            name = \"FF\"\n",
    "        elif index == 5:\n",
    "            name = \"FR\"\n",
    "\n",
    "\n",
    "        print(\"start  special_data_requests \" + str(index))\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "\n",
    "        x = 0\n",
    "        count = 0  # um zu zelehn wie oft rcognition aufgerufen wurde\n",
    "        help = False  # um zu gucken ob schon eine csv erstellt wurde\n",
    "        file = Path(self.pre_past_other)\n",
    "        if file.is_file():\n",
    "            print(\"csv schon erstellt\")\n",
    "            help = True\n",
    "\n",
    "        result = 0\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "                id = dataset['subj_counter_global'][i]\n",
    "\n",
    "                if self.is_nan(id):\n",
    "                    id = dataset['subj_counter_global'][i+3]\n",
    "\n",
    "\n",
    "                # wenn quasi die richtige antwort gegeben wurde\n",
    "                if dataset['recognition_evaluation'][i] == str(index) or dataset['recognition_evaluation'][i] == index:\n",
    "                    result += 1\n",
    "\n",
    "                count += 1\n",
    "                if count == 90:\n",
    "                    if not help:\n",
    "                        id = dataset['subj_counter_global'][i]\n",
    "                        data = {'id': [id],\n",
    "                                name : [int(result)]\n",
    "                                }\n",
    "                        df = pd.DataFrame(data, columns=['id', name])\n",
    "                        df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                        help = True\n",
    "                        x += 1\n",
    "                    else:\n",
    "\n",
    "                        id = dataset['subj_counter_global'][i]\n",
    "                        df = pd.read_csv(self.pre_past_other, sep=';', dtype='unicode')\n",
    "                        df._set_value(x, \"id\", id)\n",
    "                        df._set_value(x, name, int(result))\n",
    "\n",
    "\n",
    "                        df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                        x += 1\n",
    "\n",
    "                    count = 0\n",
    "                    result = 0\n",
    "\n",
    "    \"\"\"this method inserts several values from the Labvanced and Unipark table into the results table\"\"\"\n",
    "    def merge_result(self):\n",
    "        #get data\n",
    "        # initilize\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        # gucke ob tabellen schon zusammengefuegt wurden, ansonsten füge sie zusammen\n",
    "        dic = {}\n",
    "        values = []\n",
    "        \"\"\"try:\n",
    "            k = dataset['VPCode'][33]\n",
    "        except KeyError:\n",
    "            self.merge()\"\"\"\n",
    "\n",
    "        #get data from LD\n",
    "        old_id = 0\n",
    "        last_id=dataset['subj_counter_global'][count_rows-1]\n",
    "        for i in range(count_rows):\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            if id != old_id:\n",
    "\n",
    "                values.append(dataset['ParticipantCode'][i])\n",
    "                group = dataset['group_name'][i]\n",
    "                if not self.is_nan(group) and not self.is_nan(dataset['Gender1'][i]) :\n",
    "                    gr_nr = int(list(group)[list(group).__len__() - 1])\n",
    "                    gender = dataset['Gender1'][i]\n",
    "                    gen = 0\n",
    "                    if gender.startswith('W') or gender.startswith('w') or gender.startswith('F') or gender.startswith('f'):\n",
    "                        gen = 1\n",
    "                    elif gender.startswith('M') or gender.startswith('m'):\n",
    "                        gen = 2\n",
    "                    elif gender.startswith('D') or gender.startswith('d'):\n",
    "                        gen = 88\n",
    "\n",
    "                    values.append(gr_nr)\n",
    "                    values.append(int(gen))\n",
    "                    values.append(dataset['Age1'][i])\n",
    "                    #print(str(values[0])+ \" \" + str(values[3]))\n",
    "                    dic.update({int(float(dataset['subj_counter_global'][i])): values})\n",
    "                    values = []\n",
    "                    old_id = id\n",
    "\n",
    "                values = []\n",
    "            else:\n",
    "                values = []\n",
    "\n",
    "        # get data from Unipark\n",
    "        self.insert_subjcounter_in_second_path()\n",
    "        unipark = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows_unipark = unipark.shape[0]\n",
    "        dic_ud = {}\n",
    "        infos = []\n",
    "        names = ['K_Mittelwert', 'PW_Mittelwert', 'SL_Mittelwert', 'A_Mittelwert', 'SA_Mittelwert', 'PB_Mittelwert', 'PWB_Mittelwert', 'self_esteem', 'social_psycologic_wellbeing', 'wissenaufgabentyp', 'BAMA', 'Semester', 'Studiengang', 'Student', 'Deutschkenntnisse', 'Bearbeitung']\n",
    "        for i in range(count_rows_unipark):\n",
    "            if not self.is_nan(unipark['subject_counter'][i]):\n",
    "                for s in names:\n",
    "                    infos.append(unipark[s][i])\n",
    "\n",
    "                dic_ud.update({int(float(unipark['subject_counter'][i])): infos})\n",
    "\n",
    "            infos = []\n",
    "\n",
    "        # insert data\n",
    "        print(dic_ud)\n",
    "        df = pd.read_csv(self.pre_past_other, sep=';', dtype='unicode')\n",
    "        count_rows_result = dataset.shape[0]\n",
    "        for i in range(count_rows_result):\n",
    "            try:\n",
    "                if not self.is_nan(df['id'][i]):\n",
    "                    id = int(float(df['id'][i]))\n",
    "                    LD = dic[id]\n",
    "                    UD = dic_ud[id]\n",
    "                    df._set_value(i, \"VPCode\", LD[0])\n",
    "                    df._set_value(i, \"Gender\", LD[2])\n",
    "                    df._set_value(i, \"Group\", LD[1])\n",
    "                    df._set_value(i, 'Age', LD[3])\n",
    "\n",
    "                    x=0\n",
    "                    for s in names:\n",
    "                        df._set_value(i, s, UD[x])\n",
    "                        x += 1\n",
    "\n",
    "\n",
    "            except KeyError:\n",
    "                l =0\n",
    "\n",
    "        df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "\n",
    "    \"\"\"this method inserts the subjectcounter into the Unipark table to generate a foreign key\"\"\"\n",
    "    def insert_subjcounter_in_second_path(self):\n",
    "\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        dic = {}\n",
    "\n",
    "        for i in range(count_rows):\n",
    "\n",
    "            if not self.is_nan(dataset['ParticipantCode'][i]):\n",
    "\n",
    "                if list(dataset['ParticipantCode'][i])[0] != 'se' and list(dataset['ParticipantCode'][i])[0] != 'Se':\n",
    "\n",
    "                    dic.update({dataset['ParticipantCode'][i]: dataset['subj_counter_global'][i]})\n",
    "\n",
    "        print(dic)\n",
    "        df = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows_sec = df.shape[0]\n",
    "\n",
    "        sbjc = \"\"\n",
    "        for i in range(count_rows_sec):\n",
    "            code = df['VPCode'][i]\n",
    "            try:\n",
    "                sbjc = dic.__getitem__(code)\n",
    "                df._set_value(i, 'subject_counter', sbjc)\n",
    "            except KeyError:\n",
    "                for c in dic:\n",
    "                    ld = list(c)\n",
    "                    ud = list(code)\n",
    "                    if ld[0]== ud[0] and ld[1] == ud[1] and ld[ld.__len__()-1] == ud[ud.__len__()-1]:\n",
    "                        sbjc = dic.__getitem__(c)\n",
    "                        df._set_value(i, 'subject_counter', sbjc)\n",
    "\n",
    "\n",
    "        df.to_csv(self.second_path_lower, index=False, sep=';')\n",
    "        print(\"subject_counter in Uniparkdata nachgetragen\")\n",
    "\n",
    "\n",
    "    \"\"\"this method adds the column reco_ppo to the labvanced table,\n",
    "     in which an index is written from 0 to 11, depending on whether the adjective present Past,\n",
    "      other was or was not named and depending on whether 0 1 or 2 was trusted or not ticked 0 to 11\"\"\"\n",
    "    def reco_eval_full(self, name= \"reco_ppo\"):\n",
    "        print(\"start ihs\")\n",
    "        # get tabel and append new column\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';',dtype='unicode')\n",
    "        dataset[name] = \"\"\n",
    "        # get the number of columns\n",
    "        count_rows = dataset.shape[0]\n",
    "        # make list and dir to save values\n",
    "        trial_ID_ppo_ = {}\n",
    "        dict_ID_TrtialIDs = {}\n",
    "        # save the last and the old id \"subje_ctcounter\"\n",
    "        old_id = 0\n",
    "        last_id=dataset['subj_counter_global'][count_rows-1]\n",
    "        # just in time to get the end of the last section\n",
    "        count_last = 0\n",
    "        # go through all rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            # get the id of the row\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            # if the BlockName end with encode\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"encode\"):\n",
    "\n",
    "                \"\"\"for each line check if it is not the last id, if not, append the values to the list until the id changes.\n",
    "                    if the id changes add this list and the corresponding id to the dict. If the id is the last id, \n",
    "                    add the previous list to dict. and continue adding values to the list until counter 44 is reached\"\"\"\n",
    "\n",
    "                if id != last_id:\n",
    "                    if id != old_id:\n",
    "                        if old_id != 0:\n",
    "                            dict_ID_TrtialIDs.update({int(float(old_id)) : trial_ID_ppo_})\n",
    "\n",
    "                        \"\"\"trial_Ids = []\n",
    "                        trial_Ids.append(int(float(dataset['Trial_Id'][i])))\n",
    "                        old_id = id\"\"\"\n",
    "                        trial_ID_ppo_ = {}\n",
    "                        trial_ID_ppo_ = self.get_Pre_past_other(dataset, i, trial_ID_ppo_)\n",
    "                        old_id = id\n",
    "\n",
    "                    else:\n",
    "                        trial_ID_ppo_ = self.get_Pre_past_other(dataset, i, trial_ID_ppo_)\n",
    "                        old_id = id\n",
    "                else:\n",
    "                    count_last += 1\n",
    "                    if id != old_id:\n",
    "\n",
    "                        dict_ID_TrtialIDs.update({int(float(old_id)): trial_ID_ppo_})\n",
    "                        trial_Ids = []\n",
    "                        trial_ID_ppo_ = self.get_Pre_past_other(dataset, i, trial_ID_ppo_)\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last != 44:\n",
    "                        trial_ID_ppo_ = self.get_Pre_past_other(dataset, i, trial_ID_ppo_)\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last == 44:\n",
    "                        dict_ID_TrtialIDs.update({int(float(id)): trial_ID_ppo_})\n",
    "\n",
    "\n",
    "        print(str(dict_ID_TrtialIDs))\n",
    "\n",
    "        #go through the table one more time\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            # if the BlockName end with recognition\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and\\\n",
    "                    dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "\n",
    "                if not self.is_nan(dataset['subj_counter_global'][i]) and dataset['subj_counter_global'][i] != \"\" and\\\n",
    "                        dataset['subj_counter_global'][i] != \" \" and dataset['subj_counter_global'][i] != None:\n",
    "\n",
    "                     #get the appropriate list from the dict. to see if the Triaal id has been used before.\n",
    "                     #Try catch, as it is possible that there may be entries for recognition of a person but not for encode\n",
    "\n",
    "                    try:\n",
    "                        trial_Id_dic = dict_ID_TrtialIDs[int(float(dataset['subj_counter_global'][i]))]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    #get values to evaluate the output\n",
    "                    guess = dataset['RemKnoGue_55'][i]\n",
    "                    trial_Id = int(float(dataset['Trial_Id'][i]))\n",
    "\n",
    "                    # evaluate the result of recognition and write it in the new column\n",
    "                    evaluate = self.evaluate_reco_pre_past_other(guess, trial_Id_dic, trial_Id)\n",
    "                    dataset._set_value(i, name, evaluate)\n",
    "\n",
    "\n",
    "        dataset.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "\n",
    "\n",
    "    \"\"\"this method updates the passed diconary with the respective \n",
    "    value from one of the 6 lines for Pre past or Other\"\"\"\n",
    "    def get_Pre_past_other(self, dataset, i, dic_trial_ppo):\n",
    "\n",
    "        if not self.is_nan(dataset['02_factor_Pas-Oth-Pre'][i]) and dataset['02_factor_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['02_factor_Pas-Oth-Pre'][i] != \"\" and dataset['02_factor_Pas-Oth-Pre'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['02_factor_Pas-Oth-Pre'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Pr_Pa_Oth'][i]) and dataset['factor02_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['factor02_Pr_Pa_Oth'][i] != \"\" and dataset['factor02_Pr_Pa_Oth'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['factor02_Pr_Pa_Oth'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Oth-Pre-Pas'][i]) and dataset['factor02_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['factor02_Oth-Pre-Pas'][i] != \"\" and dataset['factor02_Oth-Pre-Pas'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['factor02_Oth-Pre-Pas'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "        if not self.is_nan(dataset['factor1_Pr_Pa_Oth_55'][i]) and dataset['factor1_Pr_Pa_Oth_55'][i] != None and \\\n",
    "                dataset['factor1_Pr_Pa_Oth_55'][i] != \"\" and dataset['factor1_Pr_Pa_Oth_55'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['factor1_Pr_Pa_Oth_55'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "        if not self.is_nan(dataset['factor2_Oth_Pre_Pas_55'][i]) and dataset['factor2_Oth_Pre_Pas_55'][i] != None and \\\n",
    "                dataset['factor2_Oth_Pre_Pas_55'][i] != \"\" and dataset['factor2_Oth_Pre_Pas_55'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['factor2_Oth_Pre_Pas_55'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "        if not self.is_nan(dataset['factor3_Pas-Oth-Pre'][i]) and dataset['factor3_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['factor3_Pas-Oth-Pre'][i] != \"\" and dataset['factor3_Pas-Oth-Pre'][i] != \" \":\n",
    "            dic_trial_ppo.update({int(float(dataset['Trial_Id'][i])): dataset['factor3_Pas-Oth-Pre'][i]})\n",
    "\n",
    "            return dic_trial_ppo\n",
    "\n",
    "    \"\"\"this method is only for overview and evaluates the index according to the data provided\"\"\"\n",
    "    def evaluate_reco_pre_past_other(self, guess, trial_Id_dic, trial_Id):\n",
    "        # ist es in encode ?\n",
    "        ppo = ''\n",
    "        in_encode = False\n",
    "        try:\n",
    "            ppo = trial_Id_dic[trial_Id]\n",
    "            in_encode = True\n",
    "        except:\n",
    "            in_encode = False\n",
    "\n",
    "        if in_encode:\n",
    "            #Wort wurde genannt\n",
    "\n",
    "            if ppo == 'Present' or ppo == 'present':\n",
    "\n",
    "                if int(float(guess)) == 0:\n",
    "                    return 0\n",
    "                elif int(float(guess)) == 1:\n",
    "                    return 1\n",
    "                elif int(float(guess)) == 2:\n",
    "                    return 2\n",
    "\n",
    "            elif ppo == 'Past' or ppo == 'past':\n",
    "                if int(float(guess)) == 0:\n",
    "                    return 3\n",
    "                elif int(float(guess)) == 1:\n",
    "                    return 4\n",
    "                elif int(float(guess)) == 2:\n",
    "                    return 5\n",
    "\n",
    "            elif ppo == 'Other' or ppo == 'other':\n",
    "                if int(float(guess)) == 0:\n",
    "                    return 6\n",
    "                elif int(float(guess)) == 1:\n",
    "                    return 7\n",
    "                elif int(float(guess)) == 2:\n",
    "                    return 8\n",
    "\n",
    "        else:\n",
    "            #Wort wurde nicht genannt\n",
    "            if int(float(guess)) == 0:\n",
    "                return 9\n",
    "            elif int(float(guess)) == 1:\n",
    "                return 10\n",
    "            elif int(float(guess)) == 2:\n",
    "                return 11\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"this method makes the query on the created index reco_ppo\n",
    "     and inserts the respective column of the count into the result table\"\"\"\n",
    "    def special_data(self, index=1):\n",
    "        name = \"\"\n",
    "        if index == 0:\n",
    "            name = \"FP_present\"\n",
    "        elif index == 1:\n",
    "            name = \"CF_present\"\n",
    "        elif index == 2:\n",
    "            name = \"CR_present\"\n",
    "        elif index == 3:\n",
    "            name = \"FP_past\"\n",
    "        elif index == 4:\n",
    "            name = \"CF_past\"\n",
    "        elif index == 5:\n",
    "            name = \"CR_past\"\n",
    "        elif index == 6:\n",
    "            name = \"FP_other\"\n",
    "        elif index == 7:\n",
    "            name = \"CF_other\"\n",
    "        elif index == 8:\n",
    "            name = \"CR_other\"\n",
    "        elif index == 9:\n",
    "            name = \"CN\"\n",
    "        elif index == 10:\n",
    "            name = \"FF\"\n",
    "        elif index == 11:\n",
    "            name = \"FR\"\n",
    "\n",
    "\n",
    "        print(\"start  special_data_requests \" + str(index))\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "\n",
    "        x = 0\n",
    "        count = 0  # um zu zelehn wie oft rcognition aufgerufen wurde\n",
    "        help = False  # um zu gucken ob schon eine csv erstellt wurde\n",
    "        file = Path(self.pre_past_other)\n",
    "        if file.is_file():\n",
    "            print(\"csv schon erstellt\")\n",
    "            help = True\n",
    "\n",
    "        result = 0\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "                id = dataset['subj_counter_global'][i]\n",
    "\n",
    "                if self.is_nan(id):\n",
    "                    id = dataset['subj_counter_global'][i+3]\n",
    "\n",
    "\n",
    "                # wenn quasi die richtige antwort gegeben wurde\n",
    "                if dataset['reco_ppo'][i] == str(index) or dataset['reco_ppo'][i] == index:\n",
    "                    result += 1\n",
    "\n",
    "                count += 1\n",
    "                if count == 90:\n",
    "                    if not help:\n",
    "                        id = dataset['subj_counter_global'][i]\n",
    "                        data = {'id': [id],\n",
    "                                name : [int(result)]\n",
    "                                }\n",
    "                        df = pd.DataFrame(data, columns=['id', name])\n",
    "                        df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                        help = True\n",
    "                        x += 1\n",
    "                    else:\n",
    "\n",
    "                        id = dataset['subj_counter_global'][i]\n",
    "                        df = pd.read_csv(self.pre_past_other, sep=';', dtype='unicode')\n",
    "                        df._set_value(x, \"id\", id)\n",
    "                        df._set_value(x, name, int(result))\n",
    "\n",
    "\n",
    "                        df.to_csv(self.pre_past_other, index=False, sep=';')\n",
    "                        x += 1\n",
    "\n",
    "                    count = 0\n",
    "                    result = 0\n",
    "\n",
    "\n",
    "    \"\"\"Manipulatipon check, \"\"\"\n",
    "    \"\"\"this method inserts the two columns controllpast and controll present into the adjective table, \n",
    "    in which the average of all liquid values stands for present or past, per adjective.\n",
    "    This method is similar to the manipulation Chek for encode\"\"\"\n",
    "    def manipulation_encode(self):\n",
    "        print(\"start special\")\n",
    "        #self.clean_adj()\n",
    "        #adjective = self.adj_as_dic()\n",
    "\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';',dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        # make list and dir to save values\n",
    "        adjective ={}\n",
    "        prepastoth = {}\n",
    "        values = []\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            # get the id of the row\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            # if the BlockName end with encode\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"encode\"):\n",
    "                adj = self.get_adj_encode(i, dataset)\n",
    "                ppo = self.get_prepastother_encode(i, dataset)\n",
    "                liq = float(self.get_liq_encode(i, dataset))\n",
    "                try:\n",
    "                    ppoHelp = adjective[adj]\n",
    "                    try:\n",
    "                        ppoHelp.update({ppo.lower() : [ppoHelp[ppo.lower()][0] + liq, ppoHelp[ppo.lower()][1] + 1]})\n",
    "                        adjective.update({adj : ppoHelp})\n",
    "                    except KeyError:\n",
    "                        ppoHelp.update({ppo.lower() : [liq, 1]})\n",
    "                        adjective.update({adj : ppoHelp})\n",
    "\n",
    "                except KeyError:\n",
    "                    prepastoth.update({ppo.lower(): [liq, 1]})\n",
    "                    adjective.update({adj: prepastoth})\n",
    "                    prepastoth = {}\n",
    "\n",
    "        print(str(adjective))\n",
    "\n",
    "        df = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        df = df.set_index(\"Adjektiv\", drop=False)\n",
    "        column_names = ['encode_past', \"encode_present\", \"encode_other\"]\n",
    "        for p in column_names:\n",
    "            df[p] = 0.00\n",
    "\n",
    "        for i in adjective:\n",
    "            past = float(int(adjective[i]['past'][0]) / int(adjective[i]['past'][1]))\n",
    "            df[\"encode_past\"][i] = past.__round__(3)\n",
    "            present = float(int(adjective[i]['present'][0]) / int(adjective[i]['present'][1]))\n",
    "            df[\"encode_present\"][i] = present.__round__(3)\n",
    "            other = float(int(adjective[i]['other'][0]) / int(adjective[i]['other'][1]))\n",
    "            df[\"encode_other\"][i] = other.__round__(3)\n",
    "\n",
    "\n",
    "        df.to_csv(self.adj_path, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "\n",
    "    \"\"\"this method is to help you get the prepast or other value \n",
    "    from the 6 different columns each for encode\"\"\"\n",
    "    def get_prepastother_encode(self, i, dataset):\n",
    "        if not self.is_nan(dataset['02_factor_Pas-Oth-Pre'][i]) and dataset['02_factor_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['02_factor_Pas-Oth-Pre'][i] != \"\" and dataset['02_factor_Pas-Oth-Pre'][i] != \" \":\n",
    "\n",
    "            return dataset['02_factor_Pas-Oth-Pre'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Pr_Pa_Oth'][i]) and dataset['factor02_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['factor02_Pr_Pa_Oth'][i] != \"\" and dataset['factor02_Pr_Pa_Oth'][i] != \" \":\n",
    "\n",
    "            return dataset['factor02_Pr_Pa_Oth'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['factor02_Oth-Pre-Pas'][i]) and dataset['factor02_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['factor02_Oth-Pre-Pas'][i] != \"\" and dataset['factor02_Oth-Pre-Pas'][i] != \" \":\n",
    "\n",
    "            return dataset['factor02_Oth-Pre-Pas'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['factor1_Pr_Pa_Oth_55'][i]) and dataset['factor1_Pr_Pa_Oth_55'][i] != None and \\\n",
    "                dataset['factor1_Pr_Pa_Oth_55'][i] != \"\" and dataset['factor1_Pr_Pa_Oth_55'][i] != \" \":\n",
    "\n",
    "            return dataset['factor1_Pr_Pa_Oth_55'][i]\n",
    "        if not self.is_nan(dataset['factor2_Oth_Pre_Pas_55'][i]) and dataset['factor2_Oth_Pre_Pas_55'][i] != None and \\\n",
    "                dataset['factor2_Oth_Pre_Pas_55'][i] != \"\" and dataset['factor2_Oth_Pre_Pas_55'][i] != \" \":\n",
    "\n",
    "            return dataset['factor2_Oth_Pre_Pas_55'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['factor3_Pas-Oth-Pre'][i]) and dataset['factor3_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['factor3_Pas-Oth-Pre'][i] != \"\" and dataset['factor3_Pas-Oth-Pre'][i] != \" \":\n",
    "\n",
    "            return dataset['factor3_Pas-Oth-Pre'][i]\n",
    "\n",
    "    \"\"\"this method is to help you get the liq value \n",
    "    from the 6 different columns each for encode\"\"\"\n",
    "    def get_liq_encode(self, i, dataset):\n",
    "        if not self.is_nan(dataset['02_Save_likert_Oth-Pre-Pas'][i]) and dataset['02_Save_likert_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['02_Save_likert_Oth-Pre-Pas'][i] != \"\" and dataset['02_Save_likert_Oth-Pre-Pas'][i] != \" \":\n",
    "            return dataset['02_Save_likert_Oth-Pre-Pas'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['02_Save_likert_Pas-Oth-Pre'][i]) and dataset['02_Save_likert_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['02_Save_likert_Pas-Oth-Pre'][i] != \"\" and dataset['02_Save_likert_Pas-Oth-Pre'][i] != \" \":\n",
    "            return dataset['02_Save_likert_Pas-Oth-Pre'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['02_Save_likert_Pr_Pa_Oth'][i]) and dataset['02_Save_likert_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['02_Save_likert_Pr_Pa_Oth'][i] != \"\" and dataset['02_Save_likert_Pr_Pa_Oth'][i] != \" \":\n",
    "            return dataset['02_Save_likert_Pr_Pa_Oth'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Save_likert_Pr_Pa_Oth_55'][i]) and dataset['Save_likert_Pr_Pa_Oth_55'][i] != None and \\\n",
    "                dataset['Save_likert_Pr_Pa_Oth_55'][i] != \"\" and dataset['Save_likert_Pr_Pa_Oth_55'][i] != \" \":\n",
    "            return dataset['Save_likert_Pr_Pa_Oth_55'][i]\n",
    "        if not self.is_nan(dataset['Save_likert_Oth_Pre_Pas_55'][i]) and dataset['Save_likert_Oth_Pre_Pas_55'][i] != None and \\\n",
    "                dataset['Save_likert_Oth_Pre_Pas_55'][i] != \"\" and dataset['Save_likert_Oth_Pre_Pas_55'][i] != \" \":\n",
    "            return dataset['Save_likert_Oth_Pre_Pas_55'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Save_likert_Pas-Oth-Pre'][i]) and dataset['Save_likert_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['Save_likert_Pas-Oth-Pre'][i] != \"\" and dataset['Save_likert_Pas-Oth-Pre'][i] != \" \":\n",
    "            return dataset['Save_likert_Pas-Oth-Pre'][i]\n",
    "\n",
    "    \"\"\"this method is to help you get the adjective \n",
    "    from the 6 different columns each for encode\"\"\"\n",
    "    def get_adj_encode(self, i, dataset):\n",
    "        if not self.is_nan(dataset['02_Readout_Pas-Oth-Pre_0'][i]) and dataset['02_Readout_Pas-Oth-Pre_0'][i] != None and \\\n",
    "                dataset['02_Readout_Pas-Oth-Pre_0'][i] != \"\" and dataset['02_Readout_Pas-Oth-Pre_0'][i] != \" \":\n",
    "\n",
    "            return dataset['02_Readout_Pas-Oth-Pre_0'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['02_Readout_Pre-Pas-Oth'][i]) and dataset['02_Readout_Pre-Pas-Oth'][i] != None and \\\n",
    "                dataset['02_Readout_Pre-Pas-Oth'][i] != \"\" and dataset['02_Readout_Pre-Pas-Oth'][i] != \" \":\n",
    "            return dataset['02_Readout_Pre-Pas-Oth'][i]\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['02_Readout_Oth-Pre-Pas_0'][i]) and dataset['02_Readout_Oth-Pre-Pas_0'][i] != None and \\\n",
    "                dataset['02_Readout_Oth-Pre-Pas_0'][i] != \"\" and dataset['02_Readout_Oth-Pre-Pas_0'][i] != \" \":\n",
    "\n",
    "            return dataset['02_Readout_Oth-Pre-Pas_0'][i]\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['Readout_Oth_Pre_Pas_55'][i]) and dataset['Readout_Oth_Pre_Pas_55'][i] != None and \\\n",
    "                dataset['Readout_Oth_Pre_Pas_55'][i] != \"\" and dataset['Readout_Oth_Pre_Pas_55'][i] != \" \":\n",
    "\n",
    "            return dataset['Readout_Oth_Pre_Pas_55'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Readout_Pas-Oth-Pre_0'][i]) and dataset['Readout_Pas-Oth-Pre_0'][i] != None and \\\n",
    "                dataset['Readout_Pas-Oth-Pre_0'][i] != \"\" and dataset['Readout_Pas-Oth-Pre_0'][i] != \" \":\n",
    "            return dataset['Readout_Pas-Oth-Pre_0'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Readout_Pr_Pa_Oth_55'][i]) and dataset['Readout_Pr_Pa_Oth_55'][\n",
    "            i] != None and \\\n",
    "                dataset['Readout_Pr_Pa_Oth_55'][i] != \"\" and dataset['Readout_Pr_Pa_Oth_55'][i] != \" \":\n",
    "            return dataset['Readout_Pr_Pa_Oth_55'][i]\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Manipulatipon check, \"\"\"\n",
    "    \"\"\"this method inserts the two columns controllpast and controll present into the adjective table, \n",
    "    in which the average of all liquid values stands for present or past, per adjective.\n",
    "    This method is similar to the manipulation Chek for controll\"\"\"\n",
    "    def manipulation_controll(self):\n",
    "        print(\"start special\")\n",
    "        #self.clean_adj()\n",
    "\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';',dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        # make list and dir to save values\n",
    "        adjective ={}\n",
    "        prepastoth = {}\n",
    "\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"contr\"):\n",
    "                adj = self.get_adj_controll(i, dataset)\n",
    "                ppo = self.get_prepastother_controll(i, dataset)\n",
    "                liq = float(self.get_liq_controll(i, dataset))\n",
    "                try:\n",
    "                    ppoHelp = adjective[adj]\n",
    "                    try:\n",
    "                        ppoHelp.update({ppo.lower() : [ppoHelp[ppo.lower()][0] + liq, ppoHelp[ppo.lower()][1] + 1]})\n",
    "                        adjective.update({adj : ppoHelp})\n",
    "                    except KeyError:\n",
    "                        ppoHelp.update({ppo.lower() : [liq, 1]})\n",
    "                        adjective.update({adj : ppoHelp})\n",
    "\n",
    "                except KeyError:\n",
    "                    prepastoth.update({ppo.lower(): [liq, 1]})\n",
    "                    adjective.update({adj: prepastoth})\n",
    "                    prepastoth = {}\n",
    "\n",
    "        print(str(adjective))\n",
    "\n",
    "        df = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        df = df.set_index(\"Adjektiv\", drop=False)\n",
    "        column_names = ['controll_past', \"controll_present\"]\n",
    "        for p in column_names:\n",
    "            df[p] = 0.00\n",
    "\n",
    "        for i in adjective:\n",
    "            df = df.set_index(\"Adjektiv\", drop=False)\n",
    "            past = float(int(adjective[i]['past'][0]) / int(adjective[i]['past'][1]))\n",
    "            df[\"controll_past\"][i] = past.__round__(3)\n",
    "            present = float(int(adjective[i]['present'][0]) / int(adjective[i]['present'][1]))\n",
    "            df[\"controll_present\"][i] = present.__round__(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df.to_csv(self.adj_path, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "\n",
    "    \"\"\"this method is to help you get the prepast or other value \n",
    "    from the 6 different columns each for controll\"\"\"\n",
    "    def get_prepastother_controll(self, i, dataset):\n",
    "        if not self.is_nan(dataset['Manipul_02_factor_Pas-Oth-Pre'][i]) and dataset['Manipul_02_factor_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['Manipul_02_factor_Pas-Oth-Pre'][i] != \"\" and dataset['Manipul_02_factor_Pas-Oth-Pre'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_02_factor_Pas-Oth-Pre'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_factor02_Oth-Pre-Pas'][i]) and dataset['Manipul_factor02_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['Manipul_factor02_Oth-Pre-Pas'][i] != \"\" and dataset['Manipul_factor02_Oth-Pre-Pas'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_factor02_Oth-Pre-Pas'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_factor02_Pr_Pa_Oth'][i]) and dataset['Manipul_factor02_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['Manipul_factor02_Pr_Pa_Oth'][i] != \"\" and dataset['Manipul_factor02_Pr_Pa_Oth'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_factor02_Pr_Pa_Oth'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_factor1_Pr_Pa_Oth'][i]) and dataset['Manipul_factor1_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['Manipul_factor1_Pr_Pa_Oth'][i] != \"\" and dataset['Manipul_factor1_Pr_Pa_Oth'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_factor1_Pr_Pa_Oth'][i]\n",
    "        if not self.is_nan(dataset['Manipul_factor2_Oth_Pre_Pas'][i]) and dataset['Manipul_factor2_Oth_Pre_Pas'][i] != None and \\\n",
    "                dataset['Manipul_factor2_Oth_Pre_Pas'][i] != \"\" and dataset['Manipul_factor2_Oth_Pre_Pas'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_factor2_Oth_Pre_Pas'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_factor3_Pas-Oth-Pre'][i]) and dataset['Manipul_factor3_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['Manipul_factor3_Pas-Oth-Pre'][i] != \"\" and dataset['Manipul_factor3_Pas-Oth-Pre'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_factor3_Pas-Oth-Pre'][i]\n",
    "\n",
    "    \"\"\"this method is to help you get the liq value \n",
    "    from the 6 different columns each for controll\"\"\"\n",
    "    def get_liq_controll(self, i, dataset):\n",
    "        if not self.is_nan(dataset['Manipul_02_Save_likert_Oth-Pre-Pas'][i]) and dataset['Manipul_02_Save_likert_Oth-Pre-Pas'][i] != None and \\\n",
    "                dataset['Manipul_02_Save_likert_Oth-Pre-Pas'][i] != \"\" and dataset['Manipul_02_Save_likert_Oth-Pre-Pas'][i] != \" \":\n",
    "            return dataset['Manipul_02_Save_likert_Oth-Pre-Pas'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_02_Save_likert_Pas-Oth-Pre'][i]) and dataset['Manipul_02_Save_likert_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['Manipul_02_Save_likert_Pas-Oth-Pre'][i] != \"\" and dataset['Manipul_02_Save_likert_Pas-Oth-Pre'][i] != \" \":\n",
    "            return dataset['Manipul_02_Save_likert_Pas-Oth-Pre'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_02_Save_likert_Pr_Pa_Oth'][i]) and dataset['Manipul_02_Save_likert_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['Manipul_02_Save_likert_Pr_Pa_Oth'][i] != \"\" and dataset['Manipul_02_Save_likert_Pr_Pa_Oth'][i] != \" \":\n",
    "            return dataset['Manipul_02_Save_likert_Pr_Pa_Oth'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_Save_likert_Pas-Oth-Pre'][i]) and dataset['Manipul_Save_likert_Pas-Oth-Pre'][i] != None and \\\n",
    "                dataset['Manipul_Save_likert_Pas-Oth-Pre'][i] != \"\" and dataset['Manipul_Save_likert_Pas-Oth-Pre'][i] != \" \":\n",
    "            return dataset['Manipul_Save_likert_Pas-Oth-Pre'][i]\n",
    "        if not self.is_nan(dataset['Manipul_Save_likert_Pr_Pa_Oth'][i]) and dataset['Manipul_Save_likert_Pr_Pa_Oth'][i] != None and \\\n",
    "                dataset['Manipul_Save_likert_Pr_Pa_Oth'][i] != \"\" and dataset['Manipul_Save_likert_Pr_Pa_Oth'][i] != \" \":\n",
    "            return dataset['Manipul_Save_likert_Pr_Pa_Oth'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_Save_likert_Oth_Pre_Pas'][i]) and dataset['Manipul_Save_likert_Oth_Pre_Pas'][i] != None and \\\n",
    "                dataset['Manipul_Save_likert_Oth_Pre_Pas'][i] != \"\" and dataset['Manipul_Save_likert_Oth_Pre_Pas'][i] != \" \":\n",
    "            return dataset['Manipul_Save_likert_Oth_Pre_Pas'][i]\n",
    "\n",
    "    \"\"\"this method is to help you get the adjective \n",
    "    from the 6 different columns each for controll\"\"\"\n",
    "    def get_adj_controll(self, i, dataset):\n",
    "        if not self.is_nan(dataset['Manipul_02_Readout_Oth-Pre-Pas_66'][i]) and dataset['Manipul_02_Readout_Oth-Pre-Pas_66'][i] != None and \\\n",
    "                dataset['Manipul_02_Readout_Oth-Pre-Pas_66'][i] != \"\" and dataset['Manipul_02_Readout_Oth-Pre-Pas_66'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_02_Readout_Oth-Pre-Pas_66'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_02_Readout_Pas-Oth-Pre_66'][i]) and dataset['Manipul_02_Readout_Pas-Oth-Pre_66'][i] != None and \\\n",
    "                dataset['Manipul_02_Readout_Pas-Oth-Pre_66'][i] != \"\" and dataset['Manipul_02_Readout_Pas-Oth-Pre_66'][i] != \" \":\n",
    "            return dataset['Manipul_02_Readout_Pas-Oth-Pre_66'][i]\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_02_Readout_Pre-Pas-Oth_66'][i]) and dataset['Manipul_02_Readout_Pre-Pas-Oth_66'][i] != None and \\\n",
    "                dataset['Manipul_02_Readout_Pre-Pas-Oth_66'][i] != \"\" and dataset['Manipul_02_Readout_Pre-Pas-Oth_66'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_02_Readout_Pre-Pas-Oth_66'][i]\n",
    "\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_Readout_Oth_Pre_Pas_66'][i]) and dataset['Manipul_Readout_Oth_Pre_Pas_66'][i] != None and \\\n",
    "                dataset['Manipul_Readout_Oth_Pre_Pas_66'][i] != \"\" and dataset['Manipul_Readout_Oth_Pre_Pas_66'][i] != \" \":\n",
    "\n",
    "            return dataset['Manipul_Readout_Oth_Pre_Pas_66'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_Readout_Pas-Oth-Pre_66'][i]) and dataset['Manipul_Readout_Pas-Oth-Pre_66'][i] != None and \\\n",
    "                dataset['Manipul_Readout_Pas-Oth-Pre_66'][i] != \"\" and dataset['Manipul_Readout_Pas-Oth-Pre_66'][i] != \" \":\n",
    "            return dataset['Manipul_Readout_Pas-Oth-Pre_66'][i]\n",
    "\n",
    "        if not self.is_nan(dataset['Manipul_Readout_Pr_Pa_Oth_final'][i]) and dataset['Manipul_Readout_Pr_Pa_Oth_final'][i] != None and \\\n",
    "                dataset['Manipul_Readout_Pr_Pa_Oth_final'][i] != \"\" and dataset['Manipul_Readout_Pr_Pa_Oth_final'][i] != \" \":\n",
    "            return dataset['Manipul_Readout_Pr_Pa_Oth_final'][i]\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Manipulation recognition\"\"\"\n",
    "    \"\"\"this method inserts the two spades just_12 and correct_12 into the table of results,\n",
    "     this is the manipulation check for recognition. This means that it counts how often 1 or 2 was checked or \n",
    "     how often the word was correctly named and 1 or 2 was checked\"\"\"\n",
    "    def manipulation_reco(self):\n",
    "\n",
    "        print(\"start insert recognition evaluation test\")\n",
    "        # get tabel and append new column\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';', dtype='unicode')\n",
    "\n",
    "        # get the number of columns\n",
    "        count_rows = dataset.shape[0]\n",
    "        # make list and dir to save values\n",
    "        adje = []\n",
    "        dict_ID_TrtialIDs = {}\n",
    "        # save the last and the old id \"subje_ctcounter\"\n",
    "        old_id = 0\n",
    "        last_id = dataset['subj_counter_global'][count_rows - 1]\n",
    "        # just in time to get the end of the last section\n",
    "        count_last = 0\n",
    "        # go through all rows\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            # get the id of the row\n",
    "            id = dataset['subj_counter_global'][i]\n",
    "\n",
    "            # if the BlockName end with encode\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"encode\"):\n",
    "\n",
    "                if id != last_id:\n",
    "                    if id != old_id:\n",
    "                        if old_id != 0:\n",
    "                            dict_ID_TrtialIDs.update({int(float(old_id)): adje})\n",
    "\n",
    "                        adje = []\n",
    "                        adje.append(self.get_adj_encode(i, dataset))\n",
    "                        old_id = id\n",
    "                    else:\n",
    "                        adje.append(self.get_adj_encode(i, dataset))\n",
    "                        old_id = id\n",
    "                else:\n",
    "                    count_last += 1\n",
    "                    if id != old_id:\n",
    "\n",
    "                        dict_ID_TrtialIDs.update({int(float(old_id)): adje})\n",
    "                        adje = []\n",
    "                        adje.append(self.get_adj_encode(i, dataset))\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last != 44:\n",
    "                        adje.append(self.get_adj_encode(i, dataset))\n",
    "                        old_id = id\n",
    "\n",
    "                    elif count_last == 44:\n",
    "                        dict_ID_TrtialIDs.update({int(float(id)): adje})\n",
    "\n",
    "        print(dict_ID_TrtialIDs)\n",
    "        adjective = self.get_adj_as_dict(manipul=1)\n",
    "        print(adjective)\n",
    "        # go through the table one more time\n",
    "        for i in range(0, count_rows):\n",
    "\n",
    "            # if the BlockName end with recognition\n",
    "            if not self.is_nan(dataset['Block_Name'][i]) and dataset['Block_Name'][i].endswith(\"recognition\") and \\\n",
    "                    dataset['Task_Nr'][i] != 1 and dataset['Task_Nr'][i] != \"1\":\n",
    "\n",
    "                if not self.is_nan(dataset['subj_counter_global'][i]) and dataset['subj_counter_global'][i] != \"\" and \\\n",
    "                        dataset['subj_counter_global'][i] != \" \" and dataset['subj_counter_global'][i] != None:\n",
    "\n",
    "                    #get the appropriate list from the dict. to see if the Triaal id has been used before.\n",
    "                     #Try catch, as it is possible that there may be entries for recognition of a person but not for encode\n",
    "\n",
    "                    try:\n",
    "                        adjec = dict_ID_TrtialIDs[int(float(dataset['subj_counter_global'][i]))]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    # get values to evaluate the output\n",
    "                    guess = int(float(dataset['RemKnoGue_55'][i]))\n",
    "                    current_adj = dataset['Readout_Recognition_55'][i]\n",
    "                    in_encode = self.in_list(adjec, current_adj)\n",
    "                    kk = adjective[current_adj][0]\n",
    "\n",
    "                    if guess == 1 or guess == 2:\n",
    "\n",
    "                        if in_encode:\n",
    "                            adjective.update({current_adj : [kk + 1, adjective[current_adj][1]]})\n",
    "                        else:\n",
    "                            adjective.update({current_adj : [adjective[current_adj][0], adjective[current_adj][1]+1]})\n",
    "\n",
    "\n",
    "\n",
    "        df = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        df = df.set_index(\"Adjektiv\", drop=False)\n",
    "        column_names = ['correct_12', \"just_12\"]\n",
    "        for p in column_names:\n",
    "            df[p] = 0\n",
    "\n",
    "        for i in adjective:\n",
    "            df = df.set_index(\"Adjektiv\", drop=False)\n",
    "\n",
    "            df[\"correct_12\"][i] = int(adjective[i][0])\n",
    "            df[\"just_12\"][i] = int(adjective[i][1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df.to_csv(self.adj_path, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "        print(adjective)\n",
    "\n",
    "\n",
    "    \"\"\"returns true if the passed string is in the passed list\"\"\"\n",
    "    def in_list(self, list, string):\n",
    "        for i in list:\n",
    "            if i == string:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    \"\"\"this method deletes from all adjectives ä,ö,ü and any special characters\"\"\"\n",
    "    def clean_adj(self):\n",
    "        print(\"start clean adjective\")\n",
    "        dataset = pd.read_csv(self.main_path_lower, sep=';',dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "\n",
    "        #all columns to be treated\n",
    "        columns = ['02_Readout_Oth-Pre-Pas_0', '02_Readout_Pas-Oth-Pre_0', '02_Readout_Pre-Pas-Oth',\n",
    "                   'Manipul_02_Readout_Oth-Pre-Pas_66', 'Manipul_02_Readout_Pas-Oth-Pre_66',\n",
    "                   'Manipul_02_Readout_Pre-Pas-Oth_66', 'Manipul_Readout_Oth_Pre_Pas_66',\n",
    "                   'Manipul_Readout_Pas-Oth-Pre_66', 'Manipul_Readout_Pr_Pa_Oth_final',\n",
    "                   'Readout_Oth_Pre_Pas_55', 'Readout_Pas-Oth-Pre_0', 'Readout_Pr_Pa_Oth_55', \"Readout_Recognition_55\"]\n",
    "\n",
    "        #for all columns go through each line and clean the adjectives\n",
    "        for i in range(0, count_rows):\n",
    "            for c in columns:\n",
    "                if not self.is_nan(dataset[c][i]) and dataset[c][i] != None:\n",
    "                    dataset._set_value(i, c, self.clean_string(dataset[c][i]))\n",
    "\n",
    "        dataset.to_csv(self.main_path_lower, index=False, sep=';')\n",
    "\n",
    "        df = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        co_rows = df.shape[0]\n",
    "        for i in range(0, co_rows):\n",
    "            df._set_value(i, 'Adjektiv', self.clean_string(df['Adjektiv'][i]))\n",
    "\n",
    "        df.to_csv(self.adj_path, index=False, sep=';')\n",
    "\n",
    "    \"\"\"this method gets a string passed to it lists it and returns it in lower case,\n",
    "     without 'ä' 'ö' and 'ü', this is necessary because adjectives with ä,ö,ü\n",
    "      were not entered correctly in the table\"\"\"\n",
    "    def clean_string(self, str):\n",
    "        str_list = list(str.lower())\n",
    "        str = \"\"\n",
    "        for c in str_list:\n",
    "            if c == \"a\" or c == \"b\" or c == \"c\" or c == \"d\" or c == \"e\" or c == \"f\" or c == \"g\" \\\n",
    "                    or c == \"h\" or c == \"i\" or c == \"j\" or c == \"k\" or c == \"l\" or c == \"m\" or c == \"n\" \\\n",
    "                    or c == \"o\" or c == \"p\" or c == \"q\" or c == \"r\" or c == \"s\" or c == \"t\" or c == \"u\" \\\n",
    "                    or c == \"v\" or c == \"w\" or c == \"x\" or c == \"y\" or c == \"z\" or c == \"1\" or c == \"2\" \\\n",
    "                    or c == \"3\" or c == \"4\" or c == \"5\" or c == \"6\" or c == \"7\" or c == \"8\" or c == \"9\" \\\n",
    "                    or c == \"0\" or c == \"ß\" or c == \"\" or c == \"b\" or c == \"b\" or c == \"b\":\n",
    "                str += c\n",
    "        return str\n",
    "\n",
    "    \"\"\"this method returns a dictonary consisting of the adjectieves and their valence\"\"\"\n",
    "    def adj_as_dic(self):\n",
    "        dataset = pd.read_csv(self.adj_path, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        dic = {}\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            dic.update({dataset['Adjektiv'][i] : dataset['Valenz'][i]})\n",
    "\n",
    "        print(str(dic))\n",
    "        return dic\n",
    "\n",
    "    ############################################### Unipark data evaluation###################################\n",
    "    ##########################################################################################################\n",
    "    ##########################################################################################################\n",
    "\n",
    "    \"\"\"this method inserts values such as KW, PW mean value, ... into the Unipark data table a\"\"\"\n",
    "    def insert_psychological_wellbeing(self):\n",
    "        print(\"start  insert_psychological_wellbeing\")\n",
    "        dataset = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "\n",
    "        column_names = ['K_Mittelwert', 'PW_Mittelwert', 'SL_Mittelwert', 'A_Mittelwert', 'SA_Mittelwert', 'PB_Mittelwert', 'PWB_Mittelwert']\n",
    "        for i in column_names:\n",
    "            dataset[i] = 0.00\n",
    "\n",
    "        K = {  'v_27': 0,\n",
    "                'v_32': 1,\n",
    "                'v_37': 1,\n",
    "                'v_42': 0,\n",
    "                'v_45': 1,\n",
    "                'v_54': 0,\n",
    "                'v_61': 0,\n",
    "                'v_74': 1,\n",
    "                'v_78': 0\n",
    "                }\n",
    "\n",
    "        Pw = {  'v_28': 1,\n",
    "                'v_43': 1,\n",
    "                'v_46': 0,\n",
    "                'v_51': 1,\n",
    "                'v_62': 0,\n",
    "                'v_66': 1,\n",
    "                'v_75': 1,\n",
    "                'v_79': 1\n",
    "                }\n",
    "\n",
    "        SL = {  'v_33': 1,\n",
    "                'v_38': 1,\n",
    "                'v_47': 1,\n",
    "                'v_52': 1,\n",
    "                'v_55': 1,\n",
    "                'v_58': 0,\n",
    "                'v_63': 0,\n",
    "                'v_67': 0,\n",
    "                'v_71': 1\n",
    "                }\n",
    "\n",
    "        A = {  'v_31': 0,\n",
    "                'v_36': 0,\n",
    "                'v_41': 1,\n",
    "                'v_44': 0,\n",
    "                'v_50': 1,\n",
    "                'v_60': 0,\n",
    "                'v_65': 1,\n",
    "                'v_69': 1,\n",
    "                'v_77': 0\n",
    "                }\n",
    "\n",
    "        SA = {  'v_29': 0,\n",
    "                'v_34': 0,\n",
    "                'v_39': 1,\n",
    "                'v_48': 0,\n",
    "                'v_53': 0,\n",
    "                'v_56': 1,\n",
    "                'v_68': 1,\n",
    "                'v_70': 0,\n",
    "                'v_73': 0,\n",
    "                'v_76': 0\n",
    "                }\n",
    "\n",
    "        Pb = {  'v_26': 0,\n",
    "                'v_30': 1,\n",
    "                'v_35': 1,\n",
    "                'v_40': 0,\n",
    "                'v_49': 1,\n",
    "                'v_57': 1,\n",
    "                'v_59': 0,\n",
    "                'v_64': 1,\n",
    "                'v_72': 0\n",
    "                }\n",
    "\n",
    "        for i in range(0, count_rows):\n",
    "            self.evaluate_psychological(i, K, 'K_Mittelwert', dataset, True)\n",
    "            self.evaluate_psychological(i, Pw, 'PW_Mittelwert', dataset, True)\n",
    "            self.evaluate_psychological(i, SL, 'SL_Mittelwert', dataset, True)\n",
    "            self.evaluate_psychological(i, A, 'A_Mittelwert', dataset, True)\n",
    "            self.evaluate_psychological(i, SA, 'SA_Mittelwert', dataset, True)\n",
    "            self.evaluate_psychological(i, Pb, 'PB_Mittelwert', dataset, True)\n",
    "\n",
    "            dataset['PWB_Mittelwert'][i] = (self.evaluate_psychological(i, K, 'K_Mittelwert', dataset, False) + self.evaluate_psychological(i, K, 'PW_Mittelwert', dataset, False)\\\n",
    "                                           + self.evaluate_psychological(i, K, 'SL_Mittelwert', dataset, False) + self.evaluate_psychological(i, K, 'A_Mittelwert', dataset, False) \\\n",
    "                                           + self.evaluate_psychological(i, K, 'SA_Mittelwert', dataset, False) + self.evaluate_psychological(i, K, 'PB_Mittelwert', dataset, False)) / 54\n",
    "            dataset.to_csv(self.second_path_lower, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "    \"\"\"this method is only for help and evaluates the output depending on whether the data\n",
    "     needs to be turned over or not\"\"\"\n",
    "    def evaluate_psychological(self, i, colums, name, dataset, teilen):\n",
    "       if teilen :\n",
    "           sum = 0\n",
    "           for j in colums:\n",
    "               if int(colums.__getitem__(j)) == 0:\n",
    "                   # has not to be inverted\n",
    "                   sum += int(dataset[j][i])\n",
    "\n",
    "               elif int(colums.__getitem__(j)) == 1:\n",
    "                   # has to be inverted\n",
    "                   value = int(dataset[j][i])\n",
    "                   if value == 1:\n",
    "                       sum += 6\n",
    "                   elif value == 2:\n",
    "                       sum += 5\n",
    "                   elif value == 3:\n",
    "                       sum += 4\n",
    "                   elif value == 4:\n",
    "                       sum += 3\n",
    "                   elif value == 5:\n",
    "                       sum += 2\n",
    "                   elif value == 6:\n",
    "                       sum += 1\n",
    "\n",
    "           sum = sum / colums.__len__()\n",
    "           dataset[name][i] = sum.__round__(2)\n",
    "\n",
    "           # dataset.insert(i, name, sum)\n",
    "       else:\n",
    "           sum = 0\n",
    "           for j in colums:\n",
    "               if int(colums.__getitem__(j)) == 0:\n",
    "                   # has not to be inverted\n",
    "                   sum += int(dataset[j][i])\n",
    "\n",
    "               elif int(colums.__getitem__(j)) == 1:\n",
    "                   # has to be inverted\n",
    "                   value = int(dataset[j][i])\n",
    "                   if value == 1:\n",
    "                       sum += 6\n",
    "                   elif value == 2:\n",
    "                       sum += 5\n",
    "                   elif value == 3:\n",
    "                       sum += 4\n",
    "                   elif value == 4:\n",
    "                       sum += 3\n",
    "                   elif value == 5:\n",
    "                       sum += 2\n",
    "                   elif value == 6:\n",
    "                       sum += 1\n",
    "\n",
    "           return sum\n",
    "\n",
    "    \"\"\"that method evaluates self_esteem\"\"\"\n",
    "    def self_esteem(self):\n",
    "        print(\"start  self_esteem\")\n",
    "        dataset = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        dataset['self_esteem'] = 0\n",
    "        se = {  'v_80': 0,\n",
    "                'v_81': 1,\n",
    "                'v_82': 0,\n",
    "                'v_83': 0,\n",
    "                'v_84': 1,\n",
    "                'v_85': 1,\n",
    "                'v_86': 0,\n",
    "                'v_87': 1,\n",
    "                'v_88': 1,\n",
    "                'v_89': 0\n",
    "                }\n",
    "        for i in range(count_rows):\n",
    "            sum = 0\n",
    "            for j in se:\n",
    "                if int(se.__getitem__(j)) == 0:\n",
    "                    # has not to be inverted\n",
    "                    sum += int(dataset[j][i])\n",
    "\n",
    "                elif int(se.__getitem__(j)) == 1:\n",
    "                    # has to be inverted\n",
    "                    value = int(dataset[j][i])\n",
    "                    if value == 1:\n",
    "                        sum += 4\n",
    "                    elif value == 2:\n",
    "                        sum += 3\n",
    "                    elif value == 3:\n",
    "                        sum += 2\n",
    "                    elif value == 4:\n",
    "                        sum += 1\n",
    "\n",
    "            dataset['self_esteem'][i] = sum.__round__(2)\n",
    "\n",
    "        dataset.to_csv(self.second_path_lower, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "    \"\"\"that method evaluates psycologic_wellbeing\"\"\"\n",
    "    def social_psycologic_wellbeing(self):\n",
    "        pd.set_option('mode.chained_assignment', None)\n",
    "        pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "        print(\"start  social_psycologic_wellbeing\")\n",
    "        sum = 0\n",
    "        dataset = pd.read_csv(self.second_path_lower, sep=';', dtype='unicode')\n",
    "        count_rows = dataset.shape[0]\n",
    "        dataset['social_psycologic_wellbeing'] = 0\n",
    "        se = ['v_90', 'v_91', 'v_92', 'v_93', 'v_94', 'v_95', 'v_96', 'v_97']\n",
    "        for i in range(count_rows):\n",
    "            sum = 0\n",
    "            for j in se:\n",
    "                sum += int(dataset[j][i])\n",
    "\n",
    "            dataset['social_psycologic_wellbeing'][i] = sum\n",
    "        dataset.to_csv(self.second_path_lower, index=False, sep=';', float_format='%.3f', decimal='.', header=True)\n",
    "\n",
    "    \"\"\" here all methods are called in sequence\"\"\"\n",
    "    ###################################### main function - Programm start ######################################\n",
    "def main():\n",
    "\n",
    "    csv = csv_Handler()\n",
    "\n",
    "    csv.delete_empty_column()\n",
    "    csv.make_lowercase()\n",
    "    csv.merge()\n",
    "    csv.insert_recognition_evaluation()\n",
    "\n",
    "\n",
    "\n",
    "    csv.evaluate_past_present_other_test_with_valenz()\n",
    "\n",
    "    csv.insert_psychological_wellbeing()\n",
    "    csv.self_esteem()\n",
    "\n",
    "    csv.social_psycologic_wellbeing()\n",
    "    csv.insert_subjcounter_in_second_path()\n",
    "\n",
    "\n",
    "    csv.special_data_requests(0)\n",
    "    csv.special_data_requests(1)\n",
    "    csv.special_data_requests(2)\n",
    "    csv.special_data_requests(3)\n",
    "    csv.special_data_requests(4)\n",
    "    csv.special_data_requests(5)\n",
    "\n",
    "\n",
    "    csv.merge_result()\n",
    "    csv.reco_eval_full()\n",
    "    for i in range(0, 12):\n",
    "         csv.special_data(i)\n",
    "    csv.clean_adj()\n",
    "    csv.manipulation_encode()\n",
    "    csv.manipulation_controll()\n",
    "    csv.manipulation_reco()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# start of the programs\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddcf122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalAnswer_Ecncoding_questionnaire.to_csv('Data integration.csv', index=False, sep=';',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17ad66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
